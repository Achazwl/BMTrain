====================== Initialization ======================
rank :          1
local_rank :    1
world_size :    8
local_size :    8
master :        thunlp-3:39435
device :        1

====================== Initialization ============================================ Initialization ============================================ Initialization ============================================ Initialization ======================



rank :          2
local_rank :    2
world_size :    8
local_size :    8
master :        thunlp-3:39435
device :        2
rank :          4
local_rank :    4
world_size :    8
local_size :    8
master :        thunlp-3:39435
device :        4
rank :          0
local_rank :    0
world_size :    8
local_size :    8
master :        thunlp-3:39435
device :        0
rank :          7
local_rank :    7
world_size :    8
local_size :    8
master :        thunlp-3:39435
device :        7




====================== Initialization ======================
rank :          5
local_rank :    5
world_size :    8
local_size :    8
master :        thunlp-3:39435
device :        5

====================== Initialization ======================
rank :          6
local_rank :    6
world_size :    8
local_size :    8
master :        thunlp-3:39435
device :        6

====================== Initialization ======================
rank :          3
local_rank :    3
world_size :    8
local_size :    8
master :        thunlp-3:39435
device :        3

Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  125772 KB |  179020 KB |     784 MB |  677704 KB |
|       from large pool |  125770 KB |  179018 KB |     730 MB |  622304 KB |
|       from small pool |       2 KB |    3971 KB |      54 MB |   55400 KB |
|---------------------------------------------------------------------------|
| Active memory         |  125772 KB |  179020 KB |     784 MB |  677704 KB |
|       from large pool |  125770 KB |  179018 KB |     730 MB |  622304 KB |
|       from small pool |       2 KB |    3971 KB |      54 MB |   55400 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  223232 KB |  223232 KB |  223232 KB |       0 B  |
|       from large pool |  217088 KB |  217088 KB |  217088 KB |       0 B  |
|       from small pool |    6144 KB |    6144 KB |    6144 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19636 KB |   34996 KB |     886 MB |     866 MB |
|       from large pool |   17590 KB |   32950 KB |     777 MB |     759 MB |
|       from small pool |    2046 KB |    4862 KB |     109 MB |     107 MB |
|---------------------------------------------------------------------------|
| Allocations           |      38    |      47    |     410    |     372    |
|       from large pool |      34    |      36    |     180    |     146    |
|       from small pool |       4    |      15    |     230    |     226    |
|---------------------------------------------------------------------------|
| Active allocs         |      38    |      47    |     410    |     372    |
|       from large pool |      34    |      36    |     180    |     146    |
|       from small pool |       4    |      15    |     230    |     226    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      12    |      12    |      12    |       0    |
|       from large pool |       9    |       9    |       9    |       0    |
|       from small pool |       3    |       3    |       3    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       5    |       9    |     200    |     195    |
|       from large pool |       4    |       5    |     119    |     115    |
|       from small pool |       1    |       6    |      81    |      80    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[18030, 14445, 24369,  ...,  3746, 11232,  4329],
        [25745,  7888, 23520,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[10.4844,  9.8125, 12.1094,  ...,  0.0000,  0.0000,  0.0000],
        [12.8984,  8.9922, 10.2344,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 0, loss:  10.6796875
 name                                                    shape               std       mean      grad_std  grad_mean
 enc_layers.0.layernorm_before_attention.weight          (1024,)             0.0000    1.0000    66.6875   -1.6094  
 enc_layers.0.self_attention.project_q                   (1024, 1024)        0.9995    -0.0004   0.9736    -0.0010  
 enc_layers.0.self_attention.project_k                   (1024, 1024)        1.0000    -0.0003   1.0010    -0.0000  
 enc_layers.0.self_attention.project_v                   (1024, 1024)        0.9995    -0.0002   1.6533    -0.0009  
 enc_layers.0.self_attention.attention_out               (1024, 1024)        1.0010    0.0003    1.6709    -0.0014  
 enc_layers.0.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    122.5625  -7.5469  
 enc_layers.0.ff.w_0                                     (2560, 1024)        1.0000    0.0005    1.7441    0.0018   
 enc_layers.0.ff.w_1                                     (2560, 1024)        1.0000    -0.0003   1.6826    0.0018   
 enc_layers.0.ff.w_out                                   (1024, 2560)        1.0010    -0.0000   1.6807    0.0006   
 enc_layers.1.layernorm_before_attention.weight          (1024,)             0.0000    1.0000    36.3125   3.0391   
 enc_layers.1.self_attention.project_q                   (1024, 1024)        1.0010    -0.0007   0.4971    -0.0002  
 enc_layers.1.self_attention.project_k                   (1024, 1024)        1.0000    0.0014    0.4956    0.0003   
 enc_layers.1.self_attention.project_v                   (1024, 1024)        1.0000    -0.0015   0.9263    -0.0004  
 enc_layers.1.self_attention.attention_out               (1024, 1024)        0.9995    -0.0003   0.9307    -0.0002  
 enc_layers.1.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    80.1875   3.3477   
 enc_layers.1.ff.w_0                                     (2560, 1024)        0.9995    -0.0008   1.1309    -0.0003  
 enc_layers.1.ff.w_1                                     (2560, 1024)        0.9995    -0.0008   1.1055    -0.0007  
 enc_layers.1.ff.w_out                                   (1024, 2560)        1.0000    -0.0003   1.1006    0.0007   
 enc_layers.2.layernorm_before_attention.weight          (1024,)             0.0000    1.0000    27.2500   -0.6011  
 enc_layers.2.self_attention.project_q                   (1024, 1024)        1.0000    0.0015    0.3137    -0.0001  
 enc_layers.2.self_attention.project_k                   (1024, 1024)        0.9995    -0.0008   0.3242    -0.0001  
 enc_layers.2.self_attention.project_v                   (1024, 1024)        1.0000    0.0017    0.7017    0.0001   
 enc_layers.2.self_attention.attention_out               (1024, 1024)        1.0000    0.0004    0.6880    0.0003   
 enc_layers.2.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    59.2812   -2.9414  
 enc_layers.2.ff.w_0                                     (2560, 1024)        1.0000    -0.0006   0.8394    0.0000   
 enc_layers.2.ff.w_1                                     (2560, 1024)        1.0000    0.0004    0.8188    0.0007   
 enc_layers.2.ff.w_out                                   (1024, 2560)        1.0010    -0.0002   0.8086    -0.0006  
 enc_layers.3.layernorm_before_attention.weight          (1024,)             0.0000    1.0000    19.7812   0.3279   
 enc_layers.3.self_attention.project_q                   (1024, 1024)        0.9990    -0.0009   0.2377    0.0000   
 enc_layers.3.self_attention.project_k                   (1024, 1024)        1.0000    0.0002    0.2399    0.0004   
 enc_layers.3.self_attention.project_v                   (1024, 1024)        0.9995    0.0006    0.5444    0.0001   
 enc_layers.3.self_attention.attention_out               (1024, 1024)        1.0000    -0.0002   0.5439    -0.0002  
 enc_layers.3.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    45.0312   1.9873   
 enc_layers.3.ff.w_0                                     (2560, 1024)        0.9995    -0.0004   0.6660    -0.0006  
 enc_layers.3.ff.w_1                                     (2560, 1024)        1.0000    0.0014    0.6470    0.0000   
 enc_layers.3.ff.w_out                                   (1024, 2560)        0.9995    0.0012    0.6431    -0.0002  
 enc_layers.4.layernorm_before_attention.weight          (1024,)             0.0000    1.0000    16.3125   0.1796   
 enc_layers.4.self_attention.project_q                   (1024, 1024)        1.0000    -0.0015   0.1792    -0.0000  
 enc_layers.4.self_attention.project_k                   (1024, 1024)        1.0010    -0.0004   0.1814    0.0000   
 enc_layers.4.self_attention.project_v                   (1024, 1024)        0.9985    -0.0005   0.4680    0.0005   
 enc_layers.4.self_attention.attention_out               (1024, 1024)        1.0000    0.0003    0.4685    0.0003   
 enc_layers.4.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    39.1250   -1.6338  
 enc_layers.4.ff.w_0                                     (2560, 1024)        1.0000    -0.0003   0.5454    0.0004   
 enc_layers.4.ff.w_1                                     (2560, 1024)        0.9990    0.0011    0.5371    -0.0001  
 enc_layers.4.ff.w_out                                   (1024, 2560)        1.0000    -0.0005   0.5430    -0.0003  
 enc_layers.5.layernorm_before_attention.weight          (1024,)             0.0000    1.0000    14.4141   0.0316   
 enc_layers.5.self_attention.project_q                   (1024, 1024)        1.0000    -0.0003   0.1440    -0.0001  
 enc_layers.5.self_attention.project_k                   (1024, 1024)        1.0000    -0.0021   0.1488    0.0001   
 enc_layers.5.self_attention.project_v                   (1024, 1024)        0.9995    0.0009    0.4094    0.0002   
 enc_layers.5.self_attention.attention_out               (1024, 1024)        1.0000    0.0009    0.4246    -0.0002  
 enc_layers.5.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    33.4062   -0.8711  
 enc_layers.5.ff.w_0                                     (2560, 1024)        1.0010    0.0006    0.4646    0.0002   
 enc_layers.5.ff.w_1                                     (2560, 1024)        0.9995    -0.0006   0.4587    0.0002   
 enc_layers.5.ff.w_out                                   (1024, 2560)        1.0000    -0.0008   0.4634    0.0003   
 enc_layers.6.layernorm_before_attention.weight          (1024,)             0.0000    1.0000    14.6641   -0.8477  
 enc_layers.6.self_attention.project_q                   (1024, 1024)        0.9990    -0.0001   0.1285    0.0001   
 enc_layers.6.self_attention.project_k                   (1024, 1024)        0.9990    -0.0000   0.1337    -0.0001  
 enc_layers.6.self_attention.project_v                   (1024, 1024)        1.0010    0.0015    0.3860    0.0000   
 enc_layers.6.self_attention.attention_out               (1024, 1024)        1.0010    0.0003    0.3840    0.0001   
 enc_layers.6.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    29.5781   -0.5781  
 enc_layers.6.ff.w_0                                     (2560, 1024)        0.9995    0.0001    0.4001    -0.0000  
 enc_layers.6.ff.w_1                                     (2560, 1024)        0.9990    -0.0008   0.4004    -0.0000  
 enc_layers.6.ff.w_out                                   (1024, 2560)        1.0000    -0.0009   0.4006    0.0004   
 enc_layers.7.layernorm_before_attention.weight          (1024,)             0.0000    1.0000    12.1016   0.0223   
 enc_layers.7.self_attention.project_q                   (1024, 1024)        1.0000    -0.0006   0.1078    0.0001   
 enc_layers.7.self_attention.project_k                   (1024, 1024)        0.9995    0.0007    0.1094    0.0000   
 enc_layers.7.self_attention.project_v                   (1024, 1024)        0.9995    -0.0000   0.3582    -0.0001  
 enc_layers.7.self_attention.attention_out               (1024, 1024)        1.0000    0.0011    0.3660    0.0003   
 enc_layers.7.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    25.4375   -0.2939  
 enc_layers.7.ff.w_0                                     (2560, 1024)        1.0000    0.0000    0.3562    0.0001   
 enc_layers.7.ff.w_1                                     (2560, 1024)        1.0000    0.0003    0.3523    0.0001   
 enc_layers.7.ff.w_out                                   (1024, 2560)        1.0000    -0.0003   0.3586    -0.0004  
 dec_layers.0.layernorm_before_self_attention.weight     (1024,)             0.0000    1.0000    77.8125   3.6445   
 dec_layers.0.self_attention.project_q                   (1024, 1024)        0.9995    0.0002    1.2783    0.0005   
 dec_layers.0.self_attention.project_k                   (1024, 1024)        0.9995    0.0008    1.2881    0.0001   
 dec_layers.0.self_attention.project_v                   (1024, 1024)        1.0000    0.0004    1.6768    0.0039   
 dec_layers.0.self_attention.attention_out               (1024, 1024)        1.0000    0.0005    1.6934    0.0042   
 dec_layers.0.layernorm_before_cross_attention.weight    (1024,)             0.0000    1.0000    27.1562   1.0518   
 dec_layers.0.cross_attention.project_q                  (1024, 1024)        0.9985    0.0012    0.8438    0.0008   
 dec_layers.0.cross_attention.project_k                  (1024, 1024)        0.9995    0.0010    0.8511    -0.0016  
 dec_layers.0.cross_attention.project_v                  (1024, 1024)        0.9985    -0.0002   1.2959    -0.0003  
 dec_layers.0.cross_attention.attention_out              (1024, 1024)        1.0010    -0.0003   1.2676    0.0017   
 dec_layers.0.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    193.6250  -1.2920  
 dec_layers.0.ff.w_0                                     (2560, 1024)        1.0000    -0.0007   2.8789    0.0004   
 dec_layers.0.ff.w_1                                     (2560, 1024)        0.9995    -0.0001   2.7812    -0.0017  
 dec_layers.0.ff.w_out                                   (1024, 2560)        1.0000    0.0004    2.7793    -0.0017  
 dec_layers.1.layernorm_before_self_attention.weight     (1024,)             0.0000    1.0000    37.6250   1.0674   
 dec_layers.1.self_attention.project_q                   (1024, 1024)        1.0010    -0.0003   0.5840    0.0003   
 dec_layers.1.self_attention.project_k                   (1024, 1024)        1.0000    0.0010    0.5850    0.0007   
 dec_layers.1.self_attention.project_v                   (1024, 1024)        0.9990    -0.0019   0.9136    -0.0012  
 dec_layers.1.self_attention.attention_out               (1024, 1024)        1.0000    -0.0012   0.9189    0.0002   
 dec_layers.1.layernorm_before_cross_attention.weight    (1024,)             0.0000    1.0000    13.1172   0.3384   
 dec_layers.1.cross_attention.project_q                  (1024, 1024)        1.0000    0.0005    0.4114    -0.0004  
 dec_layers.1.cross_attention.project_k                  (1024, 1024)        1.0000    0.0021    0.4136    0.0000   
 dec_layers.1.cross_attention.project_v                  (1024, 1024)        0.9995    0.0013    0.6284    -0.0003  
 dec_layers.1.cross_attention.attention_out              (1024, 1024)        1.0010    0.0016    0.6323    0.0004   
 dec_layers.1.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    131.7500  -5.1250  
 dec_layers.1.ff.w_0                                     (2560, 1024)        1.0000    -0.0003   1.8857    -0.0018  
 dec_layers.1.ff.w_1                                     (2560, 1024)        1.0000    -0.0012   1.8213    0.0000   
 dec_layers.1.ff.w_out                                   (1024, 2560)        0.9995    0.0001    1.8174    0.0035   
 dec_layers.2.layernorm_before_self_attention.weight     (1024,)             0.0000    1.0000    27.2031   -0.8784  
 dec_layers.2.self_attention.project_q                   (1024, 1024)        1.0000    0.0006    0.3792    -0.0006  
 dec_layers.2.self_attention.project_k                   (1024, 1024)        1.0000    -0.0024   0.3835    0.0001   
 dec_layers.2.self_attention.project_v                   (1024, 1024)        1.0000    0.0014    0.6465    -0.0003  
 dec_layers.2.self_attention.attention_out               (1024, 1024)        1.0000    0.0004    0.6436    0.0010   
 dec_layers.2.layernorm_before_cross_attention.weight    (1024,)             0.0000    1.0000    9.0469    -0.1262  
 dec_layers.2.cross_attention.project_q                  (1024, 1024)        1.0010    -0.0007   0.2788    -0.0000  
 dec_layers.2.cross_attention.project_k                  (1024, 1024)        1.0000    0.0002    0.2771    0.0004   
 dec_layers.2.cross_attention.project_v                  (1024, 1024)        1.0000    -0.0002   0.4277    0.0001   
 dec_layers.2.cross_attention.attention_out              (1024, 1024)        0.9990    0.0006    0.4326    -0.0001  
 dec_layers.2.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    100.3750  -0.8540  
 dec_layers.2.ff.w_0                                     (2560, 1024)        1.0000    0.0007    1.3994    -0.0003  
 dec_layers.2.ff.w_1                                     (2560, 1024)        0.9995    -0.0000   1.3574    -0.0006  
 dec_layers.2.ff.w_out                                   (1024, 2560)        1.0010    0.0002    1.3516    -0.0003  
 dec_layers.3.layernorm_before_self_attention.weight     (1024,)             0.0000    1.0000    20.4531   0.1899   
 dec_layers.3.self_attention.project_q                   (1024, 1024)        1.0000    -0.0000   0.2769    -0.0003  
 dec_layers.3.self_attention.project_k                   (1024, 1024)        1.0000    -0.0024   0.2805    0.0001   
 dec_layers.3.self_attention.project_v                   (1024, 1024)        1.0010    0.0003    0.5010    0.0001   
 dec_layers.3.self_attention.attention_out               (1024, 1024)        1.0010    -0.0015   0.4966    0.0004   
 dec_layers.3.layernorm_before_cross_attention.weight    (1024,)             0.0000    1.0000    6.6719    -0.1932  
 dec_layers.3.cross_attention.project_q                  (1024, 1024)        1.0000    0.0005    0.2104    -0.0001  
 dec_layers.3.cross_attention.project_k                  (1024, 1024)        0.9995    -0.0015   0.2123    0.0000   
 dec_layers.3.cross_attention.project_v                  (1024, 1024)        1.0010    0.0014    0.3259    -0.0001  
 dec_layers.3.cross_attention.attention_out              (1024, 1024)        0.9990    -0.0005   0.3264    -0.0003  
 dec_layers.3.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    78.6875   0.9009   
 dec_layers.3.ff.w_0                                     (2560, 1024)        0.9995    -0.0009   1.1143    -0.0005  
 dec_layers.3.ff.w_1                                     (2560, 1024)        0.9995    0.0001    1.0801    0.0003   
 dec_layers.3.ff.w_out                                   (1024, 2560)        1.0000    -0.0005   1.0781    0.0009   
 dec_layers.4.layernorm_before_self_attention.weight     (1024,)             0.0000    1.0000    15.9688   -1.0996  
 dec_layers.4.self_attention.project_q                   (1024, 1024)        0.9990    -0.0009   0.2179    -0.0001  
 dec_layers.4.self_attention.project_k                   (1024, 1024)        1.0000    -0.0030   0.2206    -0.0002  
 dec_layers.4.self_attention.project_v                   (1024, 1024)        1.0000    0.0003    0.4097    -0.0001  
 dec_layers.4.self_attention.attention_out               (1024, 1024)        1.0010    0.0001    0.4087    -0.0007  
 dec_layers.4.layernorm_before_cross_attention.weight    (1024,)             0.0000    1.0000    5.5430    -0.0014  
 dec_layers.4.cross_attention.project_q                  (1024, 1024)        0.9990    0.0006    0.1713    -0.0000  
 dec_layers.4.cross_attention.project_k                  (1024, 1024)        1.0010    -0.0012   0.1708    -0.0002  
 dec_layers.4.cross_attention.project_v                  (1024, 1024)        0.9995    0.0002    0.2715    0.0001   
 dec_layers.4.cross_attention.attention_out              (1024, 1024)        1.0000    0.0003    0.2715    -0.0004  
 dec_layers.4.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    66.3125   -1.5479  
 dec_layers.4.ff.w_0                                     (2560, 1024)        1.0000    -0.0006   0.9277    -0.0008  
 dec_layers.4.ff.w_1                                     (2560, 1024)        1.0000    -0.0001   0.8965    0.0005   
 dec_layers.4.ff.w_out                                   (1024, 2560)        1.0000    -0.0000   0.8965    -0.0004  
 dec_layers.5.layernorm_before_self_attention.weight     (1024,)             0.0000    1.0000    13.6797   -0.0887  
 dec_layers.5.self_attention.project_q                   (1024, 1024)        1.0000    0.0010    0.1818    -0.0001  
 dec_layers.5.self_attention.project_k                   (1024, 1024)        0.9990    0.0008    0.1847    -0.0000  
 dec_layers.5.self_attention.project_v                   (1024, 1024)        1.0000    -0.0002   0.3362    -0.0003  
 dec_layers.5.self_attention.attention_out               (1024, 1024)        0.9990    0.0007    0.3354    -0.0001  
 dec_layers.5.layernorm_before_cross_attention.weight    (1024,)             0.0000    1.0000    4.6367    0.2457   
 dec_layers.5.cross_attention.project_q                  (1024, 1024)        1.0000    -0.0003   0.1418    -0.0000  
 dec_layers.5.cross_attention.project_k                  (1024, 1024)        0.9995    0.0014    0.1440    -0.0002  
 dec_layers.5.cross_attention.project_v                  (1024, 1024)        0.9995    -0.0013   0.2186    -0.0000  
 dec_layers.5.cross_attention.attention_out              (1024, 1024)        1.0010    0.0004    0.2175    -0.0000  
 dec_layers.5.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    55.5625   -0.8853  
 dec_layers.5.ff.w_0                                     (2560, 1024)        1.0000    -0.0006   0.7949    0.0006   
 dec_layers.5.ff.w_1                                     (2560, 1024)        1.0000    -0.0013   0.7686    0.0008   
 dec_layers.5.ff.w_out                                   (1024, 2560)        0.9990    -0.0004   0.7686    0.0007   
 dec_layers.6.layernorm_before_self_attention.weight     (1024,)             0.0000    1.0000    11.5312   0.3413   
 dec_layers.6.self_attention.project_q                   (1024, 1024)        0.9990    -0.0024   0.1573    0.0001   
 dec_layers.6.self_attention.project_k                   (1024, 1024)        1.0010    -0.0007   0.1576    0.0002   
 dec_layers.6.self_attention.project_v                   (1024, 1024)        1.0000    -0.0022   0.2915    -0.0001  
 dec_layers.6.self_attention.attention_out               (1024, 1024)        0.9985    -0.0012   0.2908    0.0003   
 dec_layers.6.layernorm_before_cross_attention.weight    (1024,)             0.0000    1.0000    4.0820    0.0895   
 dec_layers.6.cross_attention.project_q                  (1024, 1024)        1.0010    -0.0008   0.1226    0.0003   
 dec_layers.6.cross_attention.project_k                  (1024, 1024)        0.9995    0.0015    0.1259    -0.0002  
 dec_layers.6.cross_attention.project_v                  (1024, 1024)        1.0000    -0.0000   0.1902    -0.0001  
 dec_layers.6.cross_attention.attention_out              (1024, 1024)        1.0000    -0.0004   0.1897    0.0000   
 dec_layers.6.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    49.0312   -2.5801  
 dec_layers.6.ff.w_0                                     (2560, 1024)        0.9995    0.0002    0.6929    0.0000   
 dec_layers.6.ff.w_1                                     (2560, 1024)        1.0000    -0.0001   0.6665    0.0002   
 dec_layers.6.ff.w_out                                   (1024, 2560)        1.0010    0.0001    0.6680    -0.0002  
 dec_layers.7.layernorm_before_self_attention.weight     (1024,)             0.0000    1.0000    10.3125   -0.0082  
 dec_layers.7.self_attention.project_q                   (1024, 1024)        1.0000    -0.0011   0.1356    0.0004   
 dec_layers.7.self_attention.project_k                   (1024, 1024)        0.9990    0.0007    0.1372    -0.0000  
 dec_layers.7.self_attention.project_v                   (1024, 1024)        0.9995    0.0004    0.2554    0.0001   
 dec_layers.7.self_attention.attention_out               (1024, 1024)        0.9990    -0.0001   0.2520    -0.0005  
 dec_layers.7.layernorm_before_cross_attention.weight    (1024,)             0.0000    1.0000    3.5332    0.0107   
 dec_layers.7.cross_attention.project_q                  (1024, 1024)        1.0010    0.0014    0.1085    0.0001   
 dec_layers.7.cross_attention.project_k                  (1024, 1024)        1.0010    -0.0009   0.1094    -0.0001  
 dec_layers.7.cross_attention.project_v                  (1024, 1024)        1.0000    0.0008    0.1716    -0.0002  
 dec_layers.7.cross_attention.attention_out              (1024, 1024)        1.0010    0.0019    0.1692    -0.0002  
 dec_layers.7.layernorm_before_ff.weight                 (1024,)             0.0000    1.0000    43.3438   0.2430   
 dec_layers.7.ff.w_0                                     (2560, 1024)        0.9995    -0.0006   0.6143    0.0001   
 dec_layers.7.ff.w_1                                     (2560, 1024)        0.9995    0.0005    0.5938    0.0000   
 dec_layers.7.ff.w_out                                   (1024, 2560)        1.0000    0.0002    0.5913    -0.0003  
 layernorm_after_enc.weight                              (1024,)             0.0000    1.0000    61.7500   1.0615   
 layernorm_after_dec.weight                              (1024,)             0.0000    1.0000    93.6250   63.9688  
 input_embedding.weight                                  (26240, 1024)       1.0000    -0.0001   1.7305    -0.0007  
 output_projection.weight                                (26240, 1024)       1.0000    -0.0001   0.5615    -0.0000  
 position_bias_enc.weight                                (32, 32)            0.9819    -0.0423   36.2812   0.0004   
 position_bias_dec.weight                                (32, 32)            1.0176    -0.0369   43.2812   0.0041   
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 2368, 14445, 24369,  ...,  3746, 11232,  4329],
        [25745, 24710, 17794,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[10.4062,  9.6875, 11.9922,  ...,  0.0000,  0.0000,  0.0000],
        [12.8516,  8.8359,  9.9766,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 1, loss:  10.5078125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 2368, 14445, 24369,  ...,  3746, 11232,  4329],
        [25745, 24710, 16746,  ...,  1916, 16229,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[10.0391,  9.2109, 11.5078,  ...,  0.0000,  0.0000,  0.0000],
        [12.0391,  7.9375,  9.1016,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 2, loss:  10.0234375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 2368, 14445, 24369,  ...,  3746, 11232,  4329],
        [25745, 24710, 17794,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[ 9.5391,  8.6484, 10.8750,  ...,  0.0000,  0.0000,  0.0000],
        [11.1406,  7.1406,  8.1406,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 3, loss:  9.34375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 2368, 14445, 24369,  ...,  3746, 11232,  4329],
        [25745,  4994, 17794,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[ 9.1406,  8.3281, 10.4219,  ...,  0.0000,  0.0000,  0.0000],
        [10.4453,  6.5078,  7.4688,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 4, loss:  8.8828125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 2368, 14445, 24369,  ...,  3746, 11232,  4329],
        [25745,  4994, 17794,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[ 8.8750,  8.0000, 10.1797,  ...,  0.0000,  0.0000,  0.0000],
        [10.1172,  6.1328,  6.9492,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 5, loss:  8.5546875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 2368, 14445,  9892,  ...,  3746, 11232,  4329],
        [25745,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[8.2891, 7.3125, 9.2891,  ..., 0.0000, 0.0000, 0.0000],
        [9.5312, 5.4844, 6.1484,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 6, loss:  7.83984375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 2368, 14445, 21512,  ...,  3746, 11232,  4329],
        [25745,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[7.8984, 6.8125, 8.8750,  ..., 0.0000, 0.0000, 0.0000],
        [8.9453, 4.9609, 5.5039,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 7, loss:  7.3203125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 2368, 14445, 21512,  ...,  3746, 11232,  4329],
        [25745,  4994,  9916,  ...,  1916, 17898, 22852]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[7.6875, 6.6523, 8.5703,  ..., 0.0000, 0.0000, 0.0000],
        [8.6328, 4.8242, 5.1133,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 8, loss:  7.06640625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 2368, 10489,  9892,  ...,  3746, 11232,  4329],
        [25745,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[7.2305, 6.1328, 7.9727,  ..., 0.0000, 0.0000, 0.0000],
        [8.2422, 4.2656, 4.4141,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 9, loss:  6.53125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 2368, 10489,  9892,  ...,  3746, 11232,  4329],
        [25745,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[6.7500, 5.6328, 7.4258,  ..., 0.0000, 0.0000, 0.0000],
        [7.6641, 3.9414, 3.6875,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 10, loss:  5.9609375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 2368, 10489,  9892,  ...,  3746, 11232,  4329],
        [25745,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[6.3359, 5.3398, 6.9375,  ..., 0.0000, 0.0000, 0.0000],
        [7.4102, 3.5215, 3.2500,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 11, loss:  5.58984375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [16840,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[5.9961, 4.9141, 6.4805,  ..., 0.0000, 0.0000, 0.0000],
        [6.7344, 3.1113, 2.5879,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 12, loss:  5.08984375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [16840,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[5.6133, 4.5156, 5.9688,  ..., 0.0000, 0.0000, 0.0000],
        [6.2188, 2.7520, 2.2891,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 13, loss:  4.59765625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898, 22852]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[5.3281, 4.1875, 5.6953,  ..., 0.0000, 0.0000, 0.0000],
        [5.8672, 2.5293, 1.9863,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 14, loss:  4.31640625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916,  8065,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[4.9648, 3.7637, 5.1484,  ..., 0.0000, 0.0000, 0.0000],
        [5.4688, 2.1016, 1.4609,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 15, loss:  3.890625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916,  8065,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[4.6992, 3.4805, 4.7695,  ..., 0.0000, 0.0000, 0.0000],
        [5.1016, 1.7080, 1.1533,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 16, loss:  3.486328125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[4.3711, 3.2305, 4.4219,  ..., 0.0000, 0.0000, 0.0000],
        [4.8320, 1.4893, 0.9175,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 17, loss:  3.1640625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[4.0781, 2.8711, 3.9531,  ..., 0.0000, 0.0000, 0.0000],
        [4.3906, 1.2471, 0.7920,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 18, loss:  2.798828125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898, 22852]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[3.7461, 2.5078, 3.6621,  ..., 0.0000, 0.0000, 0.0000],
        [3.8867, 0.9517, 0.6587,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 19, loss:  2.466796875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[3.6074, 2.2031, 3.3887,  ..., 0.0000, 0.0000, 0.0000],
        [3.5137, 0.7271, 0.5488,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 20, loss:  2.21875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[3.2520, 1.9766, 2.9629,  ..., 0.0000, 0.0000, 0.0000],
        [3.2500, 0.5977, 0.4766,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 21, loss:  1.9462890625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[3.0449, 1.6934, 2.6074,  ..., 0.0000, 0.0000, 0.0000],
        [2.8027, 0.5205, 0.4124,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 22, loss:  1.693359375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[2.8281, 1.4277, 2.2363,  ..., 0.0000, 0.0000, 0.0000],
        [2.4805, 0.4158, 0.3220,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 23, loss:  1.4755859375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[2.5410, 1.2197, 2.0020,  ..., 0.0000, 0.0000, 0.0000],
        [2.0469, 0.3425, 0.2913,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 24, loss:  1.2646484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[2.2910, 1.0254, 1.6611,  ..., 0.0000, 0.0000, 0.0000],
        [1.6162, 0.3206, 0.2576,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 25, loss:  1.0791015625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898, 22852]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[2.1309, 0.8862, 1.4336,  ..., 0.0000, 0.0000, 0.0000],
        [1.3057, 0.2727, 0.2389,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 26, loss:  0.92919921875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[1.8613, 0.7842, 1.3057,  ..., 0.0000, 0.0000, 0.0000],
        [1.0127, 0.2330, 0.2064,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 27, loss:  0.79345703125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[1.6543, 0.6265, 1.0312,  ..., 0.0000, 0.0000, 0.0000],
        [0.7778, 0.2041, 0.1965,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 28, loss:  0.671875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[1.4443, 0.5303, 0.8779,  ..., 0.0000, 0.0000, 0.0000],
        [0.5688, 0.1710, 0.1703,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 29, loss:  0.56982421875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[1.2324, 0.4346, 0.7319,  ..., 0.0000, 0.0000, 0.0000],
        [0.3916, 0.1581, 0.1620,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 30, loss:  0.480224609375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[1.0771, 0.3628, 0.5713,  ..., 0.0000, 0.0000, 0.0000],
        [0.3574, 0.1360, 0.1494,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 31, loss:  0.404052734375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.8916, 0.3135, 0.4695,  ..., 0.0000, 0.0000, 0.0000],
        [0.2908, 0.1332, 0.1263,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 32, loss:  0.34521484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.7515, 0.2717, 0.3728,  ..., 0.0000, 0.0000, 0.0000],
        [0.2101, 0.1193, 0.1115,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 33, loss:  0.293212890625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.6528, 0.2239, 0.3403,  ..., 0.0000, 0.0000, 0.0000],
        [0.1735, 0.1099, 0.0991,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 34, loss:  0.251708984375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.5376, 0.2117, 0.2820,  ..., 0.0000, 0.0000, 0.0000],
        [0.1660, 0.0999, 0.0822,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 35, loss:  0.216064453125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.4580, 0.1771, 0.2339,  ..., 0.0000, 0.0000, 0.0000],
        [0.1344, 0.0840, 0.0773,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 36, loss:  0.1885986328125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.4033, 0.1488, 0.2031,  ..., 0.0000, 0.0000, 0.0000],
        [0.1241, 0.0867, 0.0791,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 37, loss:  0.1651611328125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.3250, 0.1395, 0.1761,  ..., 0.0000, 0.0000, 0.0000],
        [0.0980, 0.0752, 0.0572,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 38, loss:  0.1463623046875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.3000, 0.1294, 0.1472,  ..., 0.0000, 0.0000, 0.0000],
        [0.0957, 0.0714, 0.0530,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 39, loss:  0.1298828125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.2493, 0.1152, 0.1368,  ..., 0.0000, 0.0000, 0.0000],
        [0.0825, 0.0647, 0.0514,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 40, loss:  0.1163330078125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.2153, 0.1054, 0.1198,  ..., 0.0000, 0.0000, 0.0000],
        [0.0737, 0.0609, 0.0511,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 41, loss:  0.10546875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.1964, 0.0922, 0.1113,  ..., 0.0000, 0.0000, 0.0000],
        [0.0662, 0.0574, 0.0409,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 42, loss:  0.09613037109375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.1754, 0.0800, 0.0946,  ..., 0.0000, 0.0000, 0.0000],
        [0.0623, 0.0535, 0.0455,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 43, loss:  0.0882568359375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.1573, 0.0776, 0.0903,  ..., 0.0000, 0.0000, 0.0000],
        [0.0544, 0.0474, 0.0425,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 44, loss:  0.081298828125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.1381, 0.0764, 0.0857,  ..., 0.0000, 0.0000, 0.0000],
        [0.0527, 0.0446, 0.0390,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 45, loss:  0.07525634765625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.1293, 0.0714, 0.0801,  ..., 0.0000, 0.0000, 0.0000],
        [0.0493, 0.0461, 0.0388,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 46, loss:  0.07049560546875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.1229, 0.0683, 0.0684,  ..., 0.0000, 0.0000, 0.0000],
        [0.0453, 0.0420, 0.0391,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 47, loss:  0.066162109375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.1052, 0.0633, 0.0629,  ..., 0.0000, 0.0000, 0.0000],
        [0.0443, 0.0411, 0.0370,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 48, loss:  0.06231689453125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0955, 0.0605, 0.0610,  ..., 0.0000, 0.0000, 0.0000],
        [0.0467, 0.0374, 0.0359,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 49, loss:  0.058868408203125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0947, 0.0569, 0.0587,  ..., 0.0000, 0.0000, 0.0000],
        [0.0398, 0.0369, 0.0335,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 50, loss:  0.05609130859375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0879, 0.0573, 0.0545,  ..., 0.0000, 0.0000, 0.0000],
        [0.0414, 0.0380, 0.0340,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 51, loss:  0.05328369140625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0828, 0.0556, 0.0533,  ..., 0.0000, 0.0000, 0.0000],
        [0.0369, 0.0347, 0.0330,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 52, loss:  0.050994873046875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0786, 0.0485, 0.0501,  ..., 0.0000, 0.0000, 0.0000],
        [0.0350, 0.0324, 0.0318,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 53, loss:  0.0487060546875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0769, 0.0485, 0.0502,  ..., 0.0000, 0.0000, 0.0000],
        [0.0341, 0.0324, 0.0308,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 54, loss:  0.046844482421875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0745, 0.0456, 0.0450,  ..., 0.0000, 0.0000, 0.0000],
        [0.0321, 0.0311, 0.0310,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 55, loss:  0.04498291015625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0671, 0.0456, 0.0451,  ..., 0.0000, 0.0000, 0.0000],
        [0.0329, 0.0282, 0.0290,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 56, loss:  0.04339599609375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0666, 0.0450, 0.0434,  ..., 0.0000, 0.0000, 0.0000],
        [0.0319, 0.0281, 0.0275,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 57, loss:  0.04205322265625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0650, 0.0443, 0.0414,  ..., 0.0000, 0.0000, 0.0000],
        [0.0321, 0.0285, 0.0260,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 58, loss:  0.040618896484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0603, 0.0432, 0.0395,  ..., 0.0000, 0.0000, 0.0000],
        [0.0321, 0.0262, 0.0282,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 59, loss:  0.039459228515625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0598, 0.0365, 0.0386,  ..., 0.0000, 0.0000, 0.0000],
        [0.0331, 0.0253, 0.0258,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 60, loss:  0.038360595703125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0608, 0.0401, 0.0381,  ..., 0.0000, 0.0000, 0.0000],
        [0.0317, 0.0230, 0.0279,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 61, loss:  0.037261962890625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0576, 0.0388, 0.0372,  ..., 0.0000, 0.0000, 0.0000],
        [0.0314, 0.0266, 0.0266,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 62, loss:  0.036529541015625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0533, 0.0363, 0.0383,  ..., 0.0000, 0.0000, 0.0000],
        [0.0284, 0.0275, 0.0241,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 63, loss:  0.035430908203125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0530, 0.0357, 0.0353,  ..., 0.0000, 0.0000, 0.0000],
        [0.0291, 0.0251, 0.0237,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 64, loss:  0.0347900390625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0522, 0.0360, 0.0360,  ..., 0.0000, 0.0000, 0.0000],
        [0.0278, 0.0255, 0.0236,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 65, loss:  0.034027099609375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0495, 0.0349, 0.0352,  ..., 0.0000, 0.0000, 0.0000],
        [0.0302, 0.0239, 0.0216,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 66, loss:  0.033447265625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0480, 0.0357, 0.0355,  ..., 0.0000, 0.0000, 0.0000],
        [0.0304, 0.0249, 0.0230,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 67, loss:  0.032745361328125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0494, 0.0331, 0.0329,  ..., 0.0000, 0.0000, 0.0000],
        [0.0286, 0.0243, 0.0218,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 68, loss:  0.032135009765625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0466, 0.0328, 0.0355,  ..., 0.0000, 0.0000, 0.0000],
        [0.0282, 0.0199, 0.0225,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 69, loss:  0.031524658203125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0465, 0.0328, 0.0309,  ..., 0.0000, 0.0000, 0.0000],
        [0.0278, 0.0209, 0.0202,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 70, loss:  0.031036376953125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0454, 0.0328, 0.0316,  ..., 0.0000, 0.0000, 0.0000],
        [0.0263, 0.0201, 0.0208,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 71, loss:  0.030517578125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0448, 0.0316, 0.0326,  ..., 0.0000, 0.0000, 0.0000],
        [0.0267, 0.0215, 0.0209,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 72, loss:  0.030059814453125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0435, 0.0295, 0.0314,  ..., 0.0000, 0.0000, 0.0000],
        [0.0273, 0.0222, 0.0184,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 73, loss:  0.0295257568359375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0451, 0.0295, 0.0324,  ..., 0.0000, 0.0000, 0.0000],
        [0.0251, 0.0209, 0.0202,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 74, loss:  0.029144287109375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0418, 0.0302, 0.0312,  ..., 0.0000, 0.0000, 0.0000],
        [0.0220, 0.0204, 0.0192,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 75, loss:  0.028778076171875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0418, 0.0295, 0.0307,  ..., 0.0000, 0.0000, 0.0000],
        [0.0238, 0.0210, 0.0192,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 76, loss:  0.0284271240234375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0424, 0.0313, 0.0311,  ..., 0.0000, 0.0000, 0.0000],
        [0.0227, 0.0209, 0.0198,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 77, loss:  0.0280609130859375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0434, 0.0281, 0.0278,  ..., 0.0000, 0.0000, 0.0000],
        [0.0245, 0.0185, 0.0186,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 78, loss:  0.0276947021484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0409, 0.0290, 0.0284,  ..., 0.0000, 0.0000, 0.0000],
        [0.0241, 0.0213, 0.0161,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 79, loss:  0.0273590087890625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0415, 0.0281, 0.0282,  ..., 0.0000, 0.0000, 0.0000],
        [0.0235, 0.0187, 0.0184,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 80, loss:  0.0270843505859375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0418, 0.0288, 0.0280,  ..., 0.0000, 0.0000, 0.0000],
        [0.0231, 0.0204, 0.0156,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 81, loss:  0.0267486572265625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0405, 0.0281, 0.0263,  ..., 0.0000, 0.0000, 0.0000],
        [0.0261, 0.0193, 0.0159,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 82, loss:  0.0265045166015625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0405, 0.0271, 0.0269,  ..., 0.0000, 0.0000, 0.0000],
        [0.0238, 0.0187, 0.0174,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 83, loss:  0.026153564453125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0408, 0.0286, 0.0291,  ..., 0.0000, 0.0000, 0.0000],
        [0.0229, 0.0174, 0.0161,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 84, loss:  0.025909423828125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0415, 0.0266, 0.0271,  ..., 0.0000, 0.0000, 0.0000],
        [0.0240, 0.0166, 0.0165,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 85, loss:  0.025665283203125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0399, 0.0275, 0.0267,  ..., 0.0000, 0.0000, 0.0000],
        [0.0233, 0.0176, 0.0162,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 86, loss:  0.0254058837890625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0396, 0.0265, 0.0259,  ..., 0.0000, 0.0000, 0.0000],
        [0.0238, 0.0169, 0.0161,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 87, loss:  0.0251312255859375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0378, 0.0249, 0.0267,  ..., 0.0000, 0.0000, 0.0000],
        [0.0226, 0.0183, 0.0155,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 88, loss:  0.0249176025390625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0402, 0.0245, 0.0244,  ..., 0.0000, 0.0000, 0.0000],
        [0.0226, 0.0187, 0.0150,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 89, loss:  0.024658203125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0390, 0.0245, 0.0259,  ..., 0.0000, 0.0000, 0.0000],
        [0.0227, 0.0190, 0.0145,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 90, loss:  0.0244140625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0373, 0.0257, 0.0243,  ..., 0.0000, 0.0000, 0.0000],
        [0.0222, 0.0168, 0.0160,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 91, loss:  0.024169921875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0384, 0.0247, 0.0241,  ..., 0.0000, 0.0000, 0.0000],
        [0.0219, 0.0176, 0.0161,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 92, loss:  0.0240325927734375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0370, 0.0254, 0.0251,  ..., 0.0000, 0.0000, 0.0000],
        [0.0232, 0.0168, 0.0159,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 93, loss:  0.0237884521484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0362, 0.0239, 0.0240,  ..., 0.0000, 0.0000, 0.0000],
        [0.0236, 0.0174, 0.0166,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 94, loss:  0.0235748291015625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0353, 0.0234, 0.0245,  ..., 0.0000, 0.0000, 0.0000],
        [0.0214, 0.0161, 0.0162,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 95, loss:  0.02337646484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0370, 0.0234, 0.0242,  ..., 0.0000, 0.0000, 0.0000],
        [0.0223, 0.0180, 0.0161,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 96, loss:  0.0232086181640625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0361, 0.0234, 0.0230,  ..., 0.0000, 0.0000, 0.0000],
        [0.0209, 0.0161, 0.0170,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 97, loss:  0.023040771484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0367, 0.0236, 0.0232,  ..., 0.0000, 0.0000, 0.0000],
        [0.0219, 0.0170, 0.0147,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 98, loss:  0.022796630859375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0364, 0.0221, 0.0242,  ..., 0.0000, 0.0000, 0.0000],
        [0.0207, 0.0158, 0.0161,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 99, loss:  0.0225982666015625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0356, 0.0227, 0.0249,  ..., 0.0000, 0.0000, 0.0000],
        [0.0222, 0.0169, 0.0160,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 100, loss:  0.0224609375
 name                                                    shape               std       mean      grad_std  grad_mean
 enc_layers.0.layernorm_before_attention.weight          (1024,)             0.0033    1.0000    0.8975    0.0391   
 enc_layers.0.self_attention.project_q                   (1024, 1024)        0.9995    -0.0003   0.0134    -0.0000  
 enc_layers.0.self_attention.project_k                   (1024, 1024)        0.9995    -0.0003   0.0135    0.0000   
 enc_layers.0.self_attention.project_v                   (1024, 1024)        0.9995    -0.0002   0.0201    -0.0000  
 enc_layers.0.self_attention.attention_out               (1024, 1024)        1.0000    0.0003    0.0202    0.0000   
 enc_layers.0.layernorm_before_ff.weight                 (1024,)             0.0050    0.9990    1.0498    0.0348   
 enc_layers.0.ff.w_0                                     (2560, 1024)        1.0000    0.0005    0.0149    -0.0000  
 enc_layers.0.ff.w_1                                     (2560, 1024)        1.0000    -0.0003   0.0142    -0.0000  
 enc_layers.0.ff.w_out                                   (1024, 2560)        1.0010    -0.0000   0.0150    0.0000   
 enc_layers.1.layernorm_before_attention.weight          (1024,)             0.0034    1.0000    0.4419    -0.0296  
 enc_layers.1.self_attention.project_q                   (1024, 1024)        1.0010    -0.0007   0.0061    0.0000   
 enc_layers.1.self_attention.project_k                   (1024, 1024)        1.0000    0.0014    0.0061    -0.0000  
 enc_layers.1.self_attention.project_v                   (1024, 1024)        1.0000    -0.0015   0.0111    0.0000   
 enc_layers.1.self_attention.attention_out               (1024, 1024)        0.9995    -0.0003   0.0111    0.0000   
 enc_layers.1.layernorm_before_ff.weight                 (1024,)             0.0051    0.9990    0.6646    -0.0268  
 enc_layers.1.ff.w_0                                     (2560, 1024)        0.9995    -0.0008   0.0096    -0.0000  
 enc_layers.1.ff.w_1                                     (2560, 1024)        0.9995    -0.0008   0.0094    -0.0000  
 enc_layers.1.ff.w_out                                   (1024, 2560)        1.0000    -0.0003   0.0106    -0.0000  
 enc_layers.2.layernorm_before_attention.weight          (1024,)             0.0036    1.0000    0.2996    0.0138   
 enc_layers.2.self_attention.project_q                   (1024, 1024)        1.0000    0.0015    0.0037    -0.0000  
 enc_layers.2.self_attention.project_k                   (1024, 1024)        0.9995    -0.0008   0.0036    -0.0000  
 enc_layers.2.self_attention.project_v                   (1024, 1024)        0.9995    0.0017    0.0077    0.0000   
 enc_layers.2.self_attention.attention_out               (1024, 1024)        1.0000    0.0004    0.0080    0.0000   
 enc_layers.2.layernorm_before_ff.weight                 (1024,)             0.0053    1.0000    0.5366    -0.0063  
 enc_layers.2.ff.w_0                                     (2560, 1024)        1.0000    -0.0006   0.0076    -0.0000  
 enc_layers.2.ff.w_1                                     (2560, 1024)        1.0000    0.0004    0.0073    0.0000   
 enc_layers.2.ff.w_out                                   (1024, 2560)        1.0010    -0.0002   0.0080    0.0000   
 enc_layers.3.layernorm_before_attention.weight          (1024,)             0.0037    1.0010    0.2336    -0.0098  
 enc_layers.3.self_attention.project_q                   (1024, 1024)        0.9990    -0.0009   0.0029    -0.0000  
 enc_layers.3.self_attention.project_k                   (1024, 1024)        1.0000    0.0001    0.0030    -0.0000  
 enc_layers.3.self_attention.project_v                   (1024, 1024)        0.9995    0.0006    0.0061    -0.0000  
 enc_layers.3.self_attention.attention_out               (1024, 1024)        1.0000    -0.0002   0.0059    0.0000   
 enc_layers.3.layernorm_before_ff.weight                 (1024,)             0.0054    1.0010    0.4146    -0.0093  
 enc_layers.3.ff.w_0                                     (2560, 1024)        0.9995    -0.0004   0.0060    0.0000   
 enc_layers.3.ff.w_1                                     (2560, 1024)        1.0000    0.0014    0.0057    0.0000   
 enc_layers.3.ff.w_out                                   (1024, 2560)        0.9995    0.0012    0.0068    0.0000   
 enc_layers.4.layernorm_before_attention.weight          (1024,)             0.0039    1.0000    0.1726    0.0013   
 enc_layers.4.self_attention.project_q                   (1024, 1024)        1.0000    -0.0015   0.0024    0.0000   
 enc_layers.4.self_attention.project_k                   (1024, 1024)        1.0010    -0.0004   0.0024    -0.0000  
 enc_layers.4.self_attention.project_v                   (1024, 1024)        0.9985    -0.0005   0.0048    0.0000   
 enc_layers.4.self_attention.attention_out               (1024, 1024)        1.0000    0.0003    0.0049    -0.0000  
 enc_layers.4.layernorm_before_ff.weight                 (1024,)             0.0057    1.0020    0.3464    -0.0033  
 enc_layers.4.ff.w_0                                     (2560, 1024)        1.0000    -0.0003   0.0050    0.0000   
 enc_layers.4.ff.w_1                                     (2560, 1024)        0.9990    0.0011    0.0049    0.0000   
 enc_layers.4.ff.w_out                                   (1024, 2560)        1.0000    -0.0005   0.0064    0.0000   
 enc_layers.5.layernorm_before_attention.weight          (1024,)             0.0040    1.0010    0.1636    -0.0011  
 enc_layers.5.self_attention.project_q                   (1024, 1024)        1.0000    -0.0003   0.0022    0.0000   
 enc_layers.5.self_attention.project_k                   (1024, 1024)        1.0000    -0.0021   0.0022    -0.0000  
 enc_layers.5.self_attention.project_v                   (1024, 1024)        0.9995    0.0009    0.0042    -0.0000  
 enc_layers.5.self_attention.attention_out               (1024, 1024)        1.0000    0.0009    0.0042    0.0000   
 enc_layers.5.layernorm_before_ff.weight                 (1024,)             0.0056    1.0029    0.2961    -0.0196  
 enc_layers.5.ff.w_0                                     (2560, 1024)        1.0010    0.0006    0.0044    -0.0000  
 enc_layers.5.ff.w_1                                     (2560, 1024)        0.9995    -0.0006   0.0042    0.0000   
 enc_layers.5.ff.w_out                                   (1024, 2560)        1.0000    -0.0008   0.0058    -0.0000  
 enc_layers.6.layernorm_before_attention.weight          (1024,)             0.0042    1.0010    0.1354    -0.0041  
 enc_layers.6.self_attention.project_q                   (1024, 1024)        0.9990    -0.0001   0.0018    -0.0000  
 enc_layers.6.self_attention.project_k                   (1024, 1024)        0.9990    -0.0000   0.0018    -0.0000  
 enc_layers.6.self_attention.project_v                   (1024, 1024)        1.0010    0.0015    0.0036    -0.0000  
 enc_layers.6.self_attention.attention_out               (1024, 1024)        1.0010    0.0003    0.0037    -0.0000  
 enc_layers.6.layernorm_before_ff.weight                 (1024,)             0.0055    1.0039    0.2651    -0.0137  
 enc_layers.6.ff.w_0                                     (2560, 1024)        0.9995    0.0001    0.0038    -0.0000  
 enc_layers.6.ff.w_1                                     (2560, 1024)        0.9990    -0.0008   0.0037    -0.0000  
 enc_layers.6.ff.w_out                                   (1024, 2560)        1.0000    -0.0009   0.0054    0.0000   
 enc_layers.7.layernorm_before_attention.weight          (1024,)             0.0042    1.0010    0.1383    -0.0117  
 enc_layers.7.self_attention.project_q                   (1024, 1024)        1.0000    -0.0006   0.0018    0.0000   
 enc_layers.7.self_attention.project_k                   (1024, 1024)        0.9995    0.0007    0.0018    0.0000   
 enc_layers.7.self_attention.project_v                   (1024, 1024)        0.9995    -0.0000   0.0037    0.0000   
 enc_layers.7.self_attention.attention_out               (1024, 1024)        1.0000    0.0011    0.0035    -0.0000  
 enc_layers.7.layernorm_before_ff.weight                 (1024,)             0.0057    1.0039    0.2358    -0.0122  
 enc_layers.7.ff.w_0                                     (2560, 1024)        1.0000    -0.0000   0.0035    0.0000   
 enc_layers.7.ff.w_1                                     (2560, 1024)        1.0000    0.0003    0.0034    0.0000   
 enc_layers.7.ff.w_out                                   (1024, 2560)        1.0000    -0.0003   0.0051    0.0000   
 dec_layers.0.layernorm_before_self_attention.weight     (1024,)             0.0077    1.0020    1.0264    -0.2864  
 dec_layers.0.self_attention.project_q                   (1024, 1024)        0.9995    0.0002    0.0176    0.0000   
 dec_layers.0.self_attention.project_k                   (1024, 1024)        0.9995    0.0008    0.0178    -0.0000  
 dec_layers.0.self_attention.project_v                   (1024, 1024)        1.0000    0.0004    0.0229    0.0000   
 dec_layers.0.self_attention.attention_out               (1024, 1024)        1.0000    0.0005    0.0234    0.0000   
 dec_layers.0.layernorm_before_cross_attention.weight    (1024,)             0.0033    1.0098    0.4504    -0.8501  
 dec_layers.0.cross_attention.project_q                  (1024, 1024)        0.9990    0.0012    0.0149    -0.0000  
 dec_layers.0.cross_attention.project_k                  (1024, 1024)        1.0000    0.0010    0.0136    -0.0000  
 dec_layers.0.cross_attention.project_v                  (1024, 1024)        0.9985    -0.0002   0.0173    -0.0000  
 dec_layers.0.cross_attention.attention_out              (1024, 1024)        1.0010    -0.0003   0.0191    0.0000   
 dec_layers.0.layernorm_before_ff.weight                 (1024,)             0.0063    0.9932    2.6230    4.2031   
 dec_layers.0.ff.w_0                                     (2560, 1024)        0.9995    -0.0007   0.0398    0.0001   
 dec_layers.0.ff.w_1                                     (2560, 1024)        0.9995    -0.0001   0.0380    0.0000   
 dec_layers.0.ff.w_out                                   (1024, 2560)        1.0000    0.0004    0.0386    0.0000   
 dec_layers.1.layernorm_before_self_attention.weight     (1024,)             0.0072    1.0039    0.6006    -0.3230  
 dec_layers.1.self_attention.project_q                   (1024, 1024)        1.0010    -0.0003   0.0099    0.0000   
 dec_layers.1.self_attention.project_k                   (1024, 1024)        1.0000    0.0010    0.0088    0.0000   
 dec_layers.1.self_attention.project_v                   (1024, 1024)        0.9990    -0.0019   0.0126    0.0000   
 dec_layers.1.self_attention.attention_out               (1024, 1024)        1.0000    -0.0012   0.0128    -0.0000  
 dec_layers.1.layernorm_before_cross_attention.weight    (1024,)             0.0049    1.0088    0.2761    -0.3479  
 dec_layers.1.cross_attention.project_q                  (1024, 1024)        1.0010    0.0005    0.0088    -0.0000  
 dec_layers.1.cross_attention.project_k                  (1024, 1024)        1.0000    0.0021    0.0085    0.0000   
 dec_layers.1.cross_attention.project_v                  (1024, 1024)        0.9995    0.0013    0.0099    -0.0000  
 dec_layers.1.cross_attention.attention_out              (1024, 1024)        1.0010    0.0016    0.0089    -0.0000  
 dec_layers.1.layernorm_before_ff.weight                 (1024,)             0.0081    0.9961    1.7969    1.9775   
 dec_layers.1.ff.w_0                                     (2560, 1024)        1.0000    -0.0003   0.0271    0.0000   
 dec_layers.1.ff.w_1                                     (2560, 1024)        1.0000    -0.0012   0.0260    -0.0000  
 dec_layers.1.ff.w_out                                   (1024, 2560)        0.9995    0.0001    0.0270    0.0000   
 dec_layers.2.layernorm_before_self_attention.weight     (1024,)             0.0071    1.0049    0.4087    -0.3047  
 dec_layers.2.self_attention.project_q                   (1024, 1024)        1.0000    0.0006    0.0077    0.0000   
 dec_layers.2.self_attention.project_k                   (1024, 1024)        1.0000    -0.0024   0.0075    -0.0000  
 dec_layers.2.self_attention.project_v                   (1024, 1024)        1.0000    0.0014    0.0094    0.0000   
 dec_layers.2.self_attention.attention_out               (1024, 1024)        1.0000    0.0003    0.0089    -0.0000  
 dec_layers.2.layernorm_before_cross_attention.weight    (1024,)             0.0059    1.0078    0.1321    -0.0748  
 dec_layers.2.cross_attention.project_q                  (1024, 1024)        1.0010    -0.0007   0.0048    -0.0000  
 dec_layers.2.cross_attention.project_k                  (1024, 1024)        1.0010    0.0002    0.0049    -0.0000  
 dec_layers.2.cross_attention.project_v                  (1024, 1024)        1.0000    -0.0002   0.0055    -0.0000  
 dec_layers.2.cross_attention.attention_out              (1024, 1024)        0.9990    0.0006    0.0076    0.0000   
 dec_layers.2.layernorm_before_ff.weight                 (1024,)             0.0088    0.9995    1.3037    0.4976   
 dec_layers.2.ff.w_0                                     (2560, 1024)        1.0000    0.0007    0.0199    0.0000   
 dec_layers.2.ff.w_1                                     (2560, 1024)        0.9995    0.0000    0.0191    0.0000   
 dec_layers.2.ff.w_out                                   (1024, 2560)        1.0010    0.0002    0.0225    0.0000   
 dec_layers.3.layernorm_before_self_attention.weight     (1024,)             0.0072    1.0049    0.3472    -0.2622  
 dec_layers.3.self_attention.project_q                   (1024, 1024)        1.0010    -0.0000   0.0059    -0.0000  
 dec_layers.3.self_attention.project_k                   (1024, 1024)        1.0000    -0.0025   0.0064    0.0000   
 dec_layers.3.self_attention.project_v                   (1024, 1024)        1.0010    0.0003    0.0085    -0.0000  
 dec_layers.3.self_attention.attention_out               (1024, 1024)        1.0010    -0.0015   0.0086    -0.0000  
 dec_layers.3.layernorm_before_cross_attention.weight    (1024,)             0.0062    1.0068    0.1077    -0.0636  
 dec_layers.3.cross_attention.project_q                  (1024, 1024)        1.0010    0.0005    0.0033    -0.0000  
 dec_layers.3.cross_attention.project_k                  (1024, 1024)        0.9995    -0.0015   0.0037    -0.0000  
 dec_layers.3.cross_attention.project_v                  (1024, 1024)        1.0010    0.0014    0.0040    -0.0000  
 dec_layers.3.cross_attention.attention_out              (1024, 1024)        0.9990    -0.0005   0.0051    -0.0000  
 dec_layers.3.layernorm_before_ff.weight                 (1024,)             0.0085    1.0029    1.1016    -0.5186  
 dec_layers.3.ff.w_0                                     (2560, 1024)        0.9995    -0.0009   0.0171    0.0000   
 dec_layers.3.ff.w_1                                     (2560, 1024)        0.9995    0.0001    0.0164    -0.0000  
 dec_layers.3.ff.w_out                                   (1024, 2560)        1.0000    -0.0005   0.0202    0.0000   
 dec_layers.4.layernorm_before_self_attention.weight     (1024,)             0.0072    1.0059    0.3228    -0.3159  
 dec_layers.4.self_attention.project_q                   (1024, 1024)        0.9990    -0.0009   0.0056    -0.0000  
 dec_layers.4.self_attention.project_k                   (1024, 1024)        1.0000    -0.0030   0.0062    0.0000   
 dec_layers.4.self_attention.project_v                   (1024, 1024)        1.0000    0.0004    0.0078    -0.0000  
 dec_layers.4.self_attention.attention_out               (1024, 1024)        1.0010    0.0001    0.0078    -0.0000  
 dec_layers.4.layernorm_before_cross_attention.weight    (1024,)             0.0069    1.0059    0.0949    -0.0456  
 dec_layers.4.cross_attention.project_q                  (1024, 1024)        0.9990    0.0006    0.0025    0.0000   
 dec_layers.4.cross_attention.project_k                  (1024, 1024)        1.0010    -0.0012   0.0031    -0.0000  
 dec_layers.4.cross_attention.project_v                  (1024, 1024)        0.9995    0.0002    0.0034    0.0000   
 dec_layers.4.cross_attention.attention_out              (1024, 1024)        1.0000    0.0003    0.0043    -0.0000  
 dec_layers.4.layernorm_before_ff.weight                 (1024,)             0.0072    1.0068    1.0859    -1.4277  
 dec_layers.4.ff.w_0                                     (2560, 1024)        1.0010    -0.0006   0.0170    -0.0000  
 dec_layers.4.ff.w_1                                     (2560, 1024)        1.0000    -0.0001   0.0164    -0.0000  
 dec_layers.4.ff.w_out                                   (1024, 2560)        1.0000    0.0000    0.0184    -0.0000  
 dec_layers.5.layernorm_before_self_attention.weight     (1024,)             0.0071    1.0059    0.2524    -0.2607  
 dec_layers.5.self_attention.project_q                   (1024, 1024)        1.0000    0.0010    0.0038    0.0000   
 dec_layers.5.self_attention.project_k                   (1024, 1024)        0.9995    0.0008    0.0048    -0.0000  
 dec_layers.5.self_attention.project_v                   (1024, 1024)        1.0000    -0.0002   0.0070    -0.0000  
 dec_layers.5.self_attention.attention_out               (1024, 1024)        0.9990    0.0007    0.0071    -0.0000  
 dec_layers.5.layernorm_before_cross_attention.weight    (1024,)             0.0069    1.0059    0.0815    -0.0376  
 dec_layers.5.cross_attention.project_q                  (1024, 1024)        1.0000    -0.0002   0.0018    -0.0000  
 dec_layers.5.cross_attention.project_k                  (1024, 1024)        0.9995    0.0014    0.0026    0.0000   
 dec_layers.5.cross_attention.project_v                  (1024, 1024)        0.9995    -0.0013   0.0029    -0.0000  
 dec_layers.5.cross_attention.attention_out              (1024, 1024)        1.0010    0.0004    0.0019    0.0000   
 dec_layers.5.layernorm_before_ff.weight                 (1024,)             0.0063    1.0088    1.1533    -2.3457  
 dec_layers.5.ff.w_0                                     (2560, 1024)        1.0010    -0.0006   0.0167    -0.0000  
 dec_layers.5.ff.w_1                                     (2560, 1024)        1.0000    -0.0013   0.0162    0.0000   
 dec_layers.5.ff.w_out                                   (1024, 2560)        0.9990    -0.0004   0.0165    0.0000   
 dec_layers.6.layernorm_before_self_attention.weight     (1024,)             0.0075    1.0059    0.1962    -0.1943  
 dec_layers.6.self_attention.project_q                   (1024, 1024)        0.9995    -0.0025   0.0018    0.0000   
 dec_layers.6.self_attention.project_k                   (1024, 1024)        1.0020    -0.0007   0.0028    0.0000   
 dec_layers.6.self_attention.project_v                   (1024, 1024)        1.0000    -0.0022   0.0057    -0.0000  
 dec_layers.6.self_attention.attention_out               (1024, 1024)        0.9985    -0.0012   0.0065    -0.0000  
 dec_layers.6.layernorm_before_cross_attention.weight    (1024,)             0.0070    1.0059    0.0801    -0.0267  
 dec_layers.6.cross_attention.project_q                  (1024, 1024)        1.0010    -0.0008   0.0016    -0.0000  
 dec_layers.6.cross_attention.project_k                  (1024, 1024)        0.9995    0.0015    0.0023    0.0000   
 dec_layers.6.cross_attention.project_v                  (1024, 1024)        1.0000    -0.0000   0.0028    0.0000   
 dec_layers.6.cross_attention.attention_out              (1024, 1024)        1.0010    -0.0004   0.0012    0.0000   
 dec_layers.6.layernorm_before_ff.weight                 (1024,)             0.0046    1.0107    1.1885    -3.2695  
 dec_layers.6.ff.w_0                                     (2560, 1024)        1.0000    0.0002    0.0168    -0.0000  
 dec_layers.6.ff.w_1                                     (2560, 1024)        1.0000    -0.0001   0.0163    0.0000   
 dec_layers.6.ff.w_out                                   (1024, 2560)        1.0010    0.0001    0.0147    0.0000   
 dec_layers.7.layernorm_before_self_attention.weight     (1024,)             0.0074    1.0068    0.1764    -0.1471  
 dec_layers.7.self_attention.project_q                   (1024, 1024)        1.0000    -0.0011   0.0013    -0.0000  
 dec_layers.7.self_attention.project_k                   (1024, 1024)        0.9995    0.0007    0.0018    0.0000   
 dec_layers.7.self_attention.project_v                   (1024, 1024)        0.9995    0.0004    0.0047    -0.0000  
 dec_layers.7.self_attention.attention_out               (1024, 1024)        0.9990    -0.0001   0.0053    -0.0000  
 dec_layers.7.layernorm_before_cross_attention.weight    (1024,)             0.0075    1.0059    0.0826    -0.0302  
 dec_layers.7.cross_attention.project_q                  (1024, 1024)        1.0010    0.0014    0.0014    -0.0000  
 dec_layers.7.cross_attention.project_k                  (1024, 1024)        1.0010    -0.0009   0.0020    -0.0000  
 dec_layers.7.cross_attention.project_v                  (1024, 1024)        1.0000    0.0008    0.0025    0.0000   
 dec_layers.7.cross_attention.attention_out              (1024, 1024)        1.0010    0.0019    0.0007    0.0000   
 dec_layers.7.layernorm_before_ff.weight                 (1024,)             0.0039    1.0117    1.2236    -4.3125  
 dec_layers.7.ff.w_0                                     (2560, 1024)        0.9995    -0.0006   0.0172    -0.0000  
 dec_layers.7.ff.w_1                                     (2560, 1024)        1.0000    0.0005    0.0166    0.0000   
 dec_layers.7.ff.w_out                                   (1024, 2560)        1.0000    0.0002    0.0130    0.0000   
 layernorm_after_enc.weight                              (1024,)             0.0020    1.0107    0.9668    -2.7422  
 layernorm_after_dec.weight                              (1024,)             0.0024    1.0117    2.2656    -18.8594 
 input_embedding.weight                                  (26240, 1024)       1.0000    -0.0001   0.0217    0.0000   
 output_projection.weight                                (26240, 1024)       0.9980    -0.0005   0.0128    -0.0000  
 position_bias_enc.weight                                (32, 32)            0.9829    -0.0428   0.5552    0.0000   
 position_bias_dec.weight                                (32, 32)            1.0186    -0.0379   0.7944    -0.0000  
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0340, 0.0225, 0.0242,  ..., 0.0000, 0.0000, 0.0000],
        [0.0208, 0.0163, 0.0158,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 101, loss:  0.0223388671875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0334, 0.0225, 0.0225,  ..., 0.0000, 0.0000, 0.0000],
        [0.0207, 0.0169, 0.0145,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 102, loss:  0.0220794677734375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0350, 0.0228, 0.0217,  ..., 0.0000, 0.0000, 0.0000],
        [0.0190, 0.0165, 0.0160,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 103, loss:  0.0219573974609375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0350, 0.0230, 0.0229,  ..., 0.0000, 0.0000, 0.0000],
        [0.0213, 0.0164, 0.0148,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 104, loss:  0.02178955078125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0334, 0.0211, 0.0229,  ..., 0.0000, 0.0000, 0.0000],
        [0.0210, 0.0164, 0.0145,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 105, loss:  0.0216217041015625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0337, 0.0213, 0.0222,  ..., 0.0000, 0.0000, 0.0000],
        [0.0192, 0.0162, 0.0153,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 106, loss:  0.02142333984375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0327, 0.0213, 0.0218,  ..., 0.0000, 0.0000, 0.0000],
        [0.0215, 0.0160, 0.0139,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 107, loss:  0.021240234375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0327, 0.0203, 0.0212,  ..., 0.0000, 0.0000, 0.0000],
        [0.0202, 0.0173, 0.0137,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 108, loss:  0.0211181640625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0332, 0.0202, 0.0212,  ..., 0.0000, 0.0000, 0.0000],
        [0.0206, 0.0166, 0.0150,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 109, loss:  0.0209808349609375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0347, 0.0211, 0.0205,  ..., 0.0000, 0.0000, 0.0000],
        [0.0206, 0.0151, 0.0140,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 110, loss:  0.0207977294921875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0329, 0.0202, 0.0213,  ..., 0.0000, 0.0000, 0.0000],
        [0.0209, 0.0158, 0.0143,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 111, loss:  0.0207366943359375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0327, 0.0210, 0.0213,  ..., 0.0000, 0.0000, 0.0000],
        [0.0195, 0.0159, 0.0140,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 112, loss:  0.0205078125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0322, 0.0203, 0.0202,  ..., 0.0000, 0.0000, 0.0000],
        [0.0202, 0.0153, 0.0136,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 113, loss:  0.0202484130859375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0320, 0.0202, 0.0207,  ..., 0.0000, 0.0000, 0.0000],
        [0.0193, 0.0154, 0.0132,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 114, loss:  0.02020263671875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0315, 0.0195, 0.0209,  ..., 0.0000, 0.0000, 0.0000],
        [0.0198, 0.0142, 0.0128,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 115, loss:  0.02008056640625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0315, 0.0193, 0.0201,  ..., 0.0000, 0.0000, 0.0000],
        [0.0182, 0.0145, 0.0134,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 116, loss:  0.0199127197265625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0319, 0.0205, 0.0201,  ..., 0.0000, 0.0000, 0.0000],
        [0.0197, 0.0162, 0.0123,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 117, loss:  0.01983642578125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0320, 0.0199, 0.0191,  ..., 0.0000, 0.0000, 0.0000],
        [0.0199, 0.0163, 0.0126,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 118, loss:  0.0196990966796875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0300, 0.0195, 0.0201,  ..., 0.0000, 0.0000, 0.0000],
        [0.0172, 0.0140, 0.0131,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 119, loss:  0.0195770263671875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0305, 0.0193, 0.0190,  ..., 0.0000, 0.0000, 0.0000],
        [0.0192, 0.0147, 0.0124,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 120, loss:  0.01934814453125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0314, 0.0197, 0.0199,  ..., 0.0000, 0.0000, 0.0000],
        [0.0192, 0.0150, 0.0124,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 121, loss:  0.0192108154296875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0307, 0.0181, 0.0201,  ..., 0.0000, 0.0000, 0.0000],
        [0.0185, 0.0158, 0.0125,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 122, loss:  0.01910400390625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0315, 0.0187, 0.0183,  ..., 0.0000, 0.0000, 0.0000],
        [0.0178, 0.0147, 0.0118,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 123, loss:  0.0190277099609375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0303, 0.0190, 0.0185,  ..., 0.0000, 0.0000, 0.0000],
        [0.0189, 0.0158, 0.0138,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 124, loss:  0.0189056396484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0303, 0.0184, 0.0186,  ..., 0.0000, 0.0000, 0.0000],
        [0.0181, 0.0163, 0.0127,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 125, loss:  0.0187835693359375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0291, 0.0181, 0.0190,  ..., 0.0000, 0.0000, 0.0000],
        [0.0188, 0.0139, 0.0123,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 126, loss:  0.0186614990234375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0303, 0.0187, 0.0173,  ..., 0.0000, 0.0000, 0.0000],
        [0.0177, 0.0159, 0.0130,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 127, loss:  0.0185089111328125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0296, 0.0176, 0.0177,  ..., 0.0000, 0.0000, 0.0000],
        [0.0175, 0.0142, 0.0112,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 128, loss:  0.0184173583984375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0283, 0.0191, 0.0183,  ..., 0.0000, 0.0000, 0.0000],
        [0.0174, 0.0135, 0.0128,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 129, loss:  0.0182342529296875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0289, 0.0188, 0.0183,  ..., 0.0000, 0.0000, 0.0000],
        [0.0170, 0.0145, 0.0115,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 130, loss:  0.0181884765625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0296, 0.0184, 0.0184,  ..., 0.0000, 0.0000, 0.0000],
        [0.0178, 0.0136, 0.0115,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 131, loss:  0.0180816650390625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0285, 0.0174, 0.0179,  ..., 0.0000, 0.0000, 0.0000],
        [0.0158, 0.0131, 0.0119,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 132, loss:  0.0179290771484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0289, 0.0177, 0.0176,  ..., 0.0000, 0.0000, 0.0000],
        [0.0168, 0.0155, 0.0123,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 133, loss:  0.0178375244140625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0289, 0.0177, 0.0187,  ..., 0.0000, 0.0000, 0.0000],
        [0.0182, 0.0136, 0.0127,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 134, loss:  0.0177764892578125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0284, 0.0178, 0.0186,  ..., 0.0000, 0.0000, 0.0000],
        [0.0172, 0.0137, 0.0105,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 135, loss:  0.0175933837890625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0278, 0.0173, 0.0175,  ..., 0.0000, 0.0000, 0.0000],
        [0.0178, 0.0144, 0.0118,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 136, loss:  0.0175628662109375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0283, 0.0170, 0.0175,  ..., 0.0000, 0.0000, 0.0000],
        [0.0162, 0.0136, 0.0123,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 137, loss:  0.0174407958984375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0270, 0.0177, 0.0181,  ..., 0.0000, 0.0000, 0.0000],
        [0.0168, 0.0141, 0.0122,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 138, loss:  0.0172882080078125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0270, 0.0176, 0.0173,  ..., 0.0000, 0.0000, 0.0000],
        [0.0174, 0.0149, 0.0127,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 139, loss:  0.0172271728515625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0283, 0.0173, 0.0184,  ..., 0.0000, 0.0000, 0.0000],
        [0.0170, 0.0149, 0.0118,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 140, loss:  0.0171356201171875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0280, 0.0160, 0.0172,  ..., 0.0000, 0.0000, 0.0000],
        [0.0178, 0.0141, 0.0115,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 141, loss:  0.0170135498046875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0259, 0.0175, 0.0159,  ..., 0.0000, 0.0000, 0.0000],
        [0.0183, 0.0148, 0.0116,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 142, loss:  0.0169525146484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0259, 0.0173, 0.0169,  ..., 0.0000, 0.0000, 0.0000],
        [0.0176, 0.0142, 0.0118,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 143, loss:  0.016845703125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0254, 0.0169, 0.0160,  ..., 0.0000, 0.0000, 0.0000],
        [0.0173, 0.0139, 0.0112,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 144, loss:  0.0167083740234375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0256, 0.0166, 0.0171,  ..., 0.0000, 0.0000, 0.0000],
        [0.0181, 0.0153, 0.0119,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 145, loss:  0.0166778564453125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0269, 0.0157, 0.0162,  ..., 0.0000, 0.0000, 0.0000],
        [0.0174, 0.0144, 0.0108,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 146, loss:  0.0165863037109375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0260, 0.0157, 0.0173,  ..., 0.0000, 0.0000, 0.0000],
        [0.0165, 0.0140, 0.0109,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 147, loss:  0.0164947509765625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0261, 0.0154, 0.0171,  ..., 0.0000, 0.0000, 0.0000],
        [0.0168, 0.0146, 0.0118,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 148, loss:  0.0163726806640625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0251, 0.0169, 0.0159,  ..., 0.0000, 0.0000, 0.0000],
        [0.0181, 0.0144, 0.0111,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 149, loss:  0.0162506103515625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0256, 0.0177, 0.0157,  ..., 0.0000, 0.0000, 0.0000],
        [0.0171, 0.0132, 0.0125,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 150, loss:  0.0162353515625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0247, 0.0159, 0.0164,  ..., 0.0000, 0.0000, 0.0000],
        [0.0177, 0.0151, 0.0106,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 151, loss:  0.0161590576171875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0259, 0.0155, 0.0163,  ..., 0.0000, 0.0000, 0.0000],
        [0.0191, 0.0131, 0.0106,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 152, loss:  0.0160980224609375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0250, 0.0164, 0.0158,  ..., 0.0000, 0.0000, 0.0000],
        [0.0171, 0.0128, 0.0106,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 153, loss:  0.0159912109375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0255, 0.0150, 0.0159,  ..., 0.0000, 0.0000, 0.0000],
        [0.0166, 0.0130, 0.0109,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 154, loss:  0.0159759521484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0244, 0.0152, 0.0163,  ..., 0.0000, 0.0000, 0.0000],
        [0.0178, 0.0131, 0.0121,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 155, loss:  0.0158538818359375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0257, 0.0154, 0.0161,  ..., 0.0000, 0.0000, 0.0000],
        [0.0165, 0.0133, 0.0128,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 156, loss:  0.0157928466796875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0240, 0.0158, 0.0165,  ..., 0.0000, 0.0000, 0.0000],
        [0.0168, 0.0148, 0.0111,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 157, loss:  0.01568603515625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0254, 0.0152, 0.0158,  ..., 0.0000, 0.0000, 0.0000],
        [0.0169, 0.0138, 0.0108,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 158, loss:  0.0156402587890625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0242, 0.0149, 0.0163,  ..., 0.0000, 0.0000, 0.0000],
        [0.0174, 0.0128, 0.0107,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 159, loss:  0.01555633544921875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0227, 0.0149, 0.0160,  ..., 0.0000, 0.0000, 0.0000],
        [0.0171, 0.0127, 0.0111,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 160, loss:  0.01551055908203125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0235, 0.0153, 0.0161,  ..., 0.0000, 0.0000, 0.0000],
        [0.0156, 0.0122, 0.0121,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 161, loss:  0.0153961181640625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0238, 0.0152, 0.0162,  ..., 0.0000, 0.0000, 0.0000],
        [0.0156, 0.0131, 0.0112,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 162, loss:  0.01532745361328125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0234, 0.0154, 0.0170,  ..., 0.0000, 0.0000, 0.0000],
        [0.0156, 0.0127, 0.0122,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 163, loss:  0.0152740478515625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0231, 0.0161, 0.0173,  ..., 0.0000, 0.0000, 0.0000],
        [0.0157, 0.0130, 0.0120,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 164, loss:  0.0152435302734375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0235, 0.0149, 0.0162,  ..., 0.0000, 0.0000, 0.0000],
        [0.0145, 0.0128, 0.0128,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 165, loss:  0.01514434814453125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0233, 0.0143, 0.0160,  ..., 0.0000, 0.0000, 0.0000],
        [0.0163, 0.0120, 0.0121,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 166, loss:  0.0150299072265625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0231, 0.0157, 0.0160,  ..., 0.0000, 0.0000, 0.0000],
        [0.0162, 0.0136, 0.0120,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 167, loss:  0.01508331298828125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0228, 0.0156, 0.0162,  ..., 0.0000, 0.0000, 0.0000],
        [0.0161, 0.0128, 0.0136,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 168, loss:  0.01502227783203125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0217, 0.0149, 0.0153,  ..., 0.0000, 0.0000, 0.0000],
        [0.0156, 0.0116, 0.0121,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 169, loss:  0.0149383544921875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0233, 0.0142, 0.0166,  ..., 0.0000, 0.0000, 0.0000],
        [0.0159, 0.0125, 0.0118,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 170, loss:  0.0148773193359375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0211, 0.0146, 0.0160,  ..., 0.0000, 0.0000, 0.0000],
        [0.0159, 0.0130, 0.0134,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 171, loss:  0.0148468017578125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0222, 0.0142, 0.0159,  ..., 0.0000, 0.0000, 0.0000],
        [0.0148, 0.0123, 0.0119,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 172, loss:  0.01477813720703125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0226, 0.0142, 0.0155,  ..., 0.0000, 0.0000, 0.0000],
        [0.0162, 0.0134, 0.0105,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 173, loss:  0.0147552490234375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0217, 0.0148, 0.0155,  ..., 0.0000, 0.0000, 0.0000],
        [0.0163, 0.0122, 0.0111,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 174, loss:  0.01465606689453125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0222, 0.0150, 0.0158,  ..., 0.0000, 0.0000, 0.0000],
        [0.0162, 0.0121, 0.0123,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 175, loss:  0.0146636962890625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0214, 0.0141, 0.0150,  ..., 0.0000, 0.0000, 0.0000],
        [0.0163, 0.0125, 0.0117,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 176, loss:  0.0145416259765625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0206, 0.0148, 0.0147,  ..., 0.0000, 0.0000, 0.0000],
        [0.0160, 0.0116, 0.0110,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 177, loss:  0.01453399658203125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0219, 0.0143, 0.0152,  ..., 0.0000, 0.0000, 0.0000],
        [0.0168, 0.0109, 0.0117,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 178, loss:  0.01451873779296875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0214, 0.0141, 0.0159,  ..., 0.0000, 0.0000, 0.0000],
        [0.0161, 0.0124, 0.0117,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 179, loss:  0.01447296142578125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0203, 0.0141, 0.0155,  ..., 0.0000, 0.0000, 0.0000],
        [0.0154, 0.0122, 0.0114,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 180, loss:  0.01439666748046875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0214, 0.0144, 0.0142,  ..., 0.0000, 0.0000, 0.0000],
        [0.0155, 0.0121, 0.0109,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 181, loss:  0.01433563232421875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0204, 0.0136, 0.0154,  ..., 0.0000, 0.0000, 0.0000],
        [0.0157, 0.0112, 0.0103,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 182, loss:  0.01428985595703125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0206, 0.0134, 0.0160,  ..., 0.0000, 0.0000, 0.0000],
        [0.0156, 0.0124, 0.0109,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 183, loss:  0.01427459716796875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0206, 0.0134, 0.0155,  ..., 0.0000, 0.0000, 0.0000],
        [0.0150, 0.0128, 0.0110,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 184, loss:  0.01421356201171875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0206, 0.0144, 0.0152,  ..., 0.0000, 0.0000, 0.0000],
        [0.0154, 0.0120, 0.0104,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 185, loss:  0.01416778564453125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0200, 0.0147, 0.0161,  ..., 0.0000, 0.0000, 0.0000],
        [0.0161, 0.0130, 0.0119,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 186, loss:  0.01415252685546875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0197, 0.0141, 0.0146,  ..., 0.0000, 0.0000, 0.0000],
        [0.0156, 0.0117, 0.0114,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 187, loss:  0.01409912109375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0204, 0.0145, 0.0151,  ..., 0.0000, 0.0000, 0.0000],
        [0.0144, 0.0122, 0.0122,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 188, loss:  0.0140838623046875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0200, 0.0144, 0.0145,  ..., 0.0000, 0.0000, 0.0000],
        [0.0161, 0.0135, 0.0100,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 189, loss:  0.0140533447265625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0192, 0.0146, 0.0142,  ..., 0.0000, 0.0000, 0.0000],
        [0.0158, 0.0125, 0.0105,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 190, loss:  0.0140228271484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0200, 0.0142, 0.0149,  ..., 0.0000, 0.0000, 0.0000],
        [0.0157, 0.0114, 0.0117,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 191, loss:  0.0140228271484375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0194, 0.0147, 0.0148,  ..., 0.0000, 0.0000, 0.0000],
        [0.0149, 0.0122, 0.0105,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 192, loss:  0.0139312744140625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0182, 0.0139, 0.0146,  ..., 0.0000, 0.0000, 0.0000],
        [0.0145, 0.0124, 0.0112,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 193, loss:  0.0139007568359375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0189, 0.0141, 0.0141,  ..., 0.0000, 0.0000, 0.0000],
        [0.0151, 0.0126, 0.0113,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 194, loss:  0.0139007568359375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0192, 0.0139, 0.0149,  ..., 0.0000, 0.0000, 0.0000],
        [0.0140, 0.0133, 0.0127,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 195, loss:  0.01386260986328125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0186, 0.0151, 0.0146,  ..., 0.0000, 0.0000, 0.0000],
        [0.0147, 0.0127, 0.0125,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 196, loss:  0.0138092041015625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0183, 0.0139, 0.0155,  ..., 0.0000, 0.0000, 0.0000],
        [0.0145, 0.0134, 0.0120,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 197, loss:  0.0138092041015625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0185, 0.0137, 0.0158,  ..., 0.0000, 0.0000, 0.0000],
        [0.0139, 0.0122, 0.0113,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 198, loss:  0.01378631591796875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0190, 0.0136, 0.0149,  ..., 0.0000, 0.0000, 0.0000],
        [0.0139, 0.0124, 0.0112,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 199, loss:  0.0137786865234375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 14945,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0183, 0.0151, 0.0152,  ..., 0.0000, 0.0000, 0.0000],
        [0.0147, 0.0122, 0.0118,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 200, loss:  0.01374053955078125
 name                                                    shape               std       mean      grad_std  grad_mean
 enc_layers.0.layernorm_before_attention.weight          (1024,)             0.0033    1.0000    0.7339    -0.0044  
 enc_layers.0.self_attention.project_q                   (1024, 1024)        0.9995    -0.0003   0.0097    -0.0000  
 enc_layers.0.self_attention.project_k                   (1024, 1024)        0.9995    -0.0003   0.0097    0.0000   
 enc_layers.0.self_attention.project_v                   (1024, 1024)        0.9995    -0.0002   0.0169    -0.0000  
 enc_layers.0.self_attention.attention_out               (1024, 1024)        1.0000    0.0003    0.0170    -0.0000  
 enc_layers.0.layernorm_before_ff.weight                 (1024,)             0.0050    0.9985    0.9170    0.0325   
 enc_layers.0.ff.w_0                                     (2560, 1024)        1.0000    0.0005    0.0124    0.0000   
 enc_layers.0.ff.w_1                                     (2560, 1024)        1.0000    -0.0003   0.0120    -0.0000  
 enc_layers.0.ff.w_out                                   (1024, 2560)        1.0010    -0.0000   0.0124    -0.0000  
 enc_layers.1.layernorm_before_attention.weight          (1024,)             0.0034    1.0000    0.3904    -0.0016  
 enc_layers.1.self_attention.project_q                   (1024, 1024)        1.0010    -0.0007   0.0049    0.0000   
 enc_layers.1.self_attention.project_k                   (1024, 1024)        1.0000    0.0014    0.0050    0.0000   
 enc_layers.1.self_attention.project_v                   (1024, 1024)        1.0000    -0.0015   0.0094    -0.0000  
 enc_layers.1.self_attention.attention_out               (1024, 1024)        0.9990    -0.0003   0.0093    -0.0000  
 enc_layers.1.layernorm_before_ff.weight                 (1024,)             0.0051    0.9990    0.5664    -0.0386  
 enc_layers.1.ff.w_0                                     (2560, 1024)        0.9995    -0.0008   0.0081    0.0000   
 enc_layers.1.ff.w_1                                     (2560, 1024)        0.9995    -0.0008   0.0078    0.0000   
 enc_layers.1.ff.w_out                                   (1024, 2560)        1.0000    -0.0003   0.0087    -0.0000  
 enc_layers.2.layernorm_before_attention.weight          (1024,)             0.0036    1.0000    0.2419    -0.0037  
 enc_layers.2.self_attention.project_q                   (1024, 1024)        1.0000    0.0015    0.0031    0.0000   
 enc_layers.2.self_attention.project_k                   (1024, 1024)        0.9995    -0.0008   0.0030    -0.0000  
 enc_layers.2.self_attention.project_v                   (1024, 1024)        0.9995    0.0017    0.0066    -0.0000  
 enc_layers.2.self_attention.attention_out               (1024, 1024)        1.0000    0.0004    0.0066    0.0000   
 enc_layers.2.layernorm_before_ff.weight                 (1024,)             0.0053    1.0000    0.4214    -0.0269  
 enc_layers.2.ff.w_0                                     (2560, 1024)        1.0000    -0.0006   0.0060    -0.0000  
 enc_layers.2.ff.w_1                                     (2560, 1024)        1.0000    0.0004    0.0059    -0.0000  
 enc_layers.2.ff.w_out                                   (1024, 2560)        1.0000    -0.0002   0.0067    -0.0000  
 enc_layers.3.layernorm_before_attention.weight          (1024,)             0.0037    1.0000    0.1862    0.0145   
 enc_layers.3.self_attention.project_q                   (1024, 1024)        0.9990    -0.0009   0.0025    -0.0000  
 enc_layers.3.self_attention.project_k                   (1024, 1024)        1.0000    0.0001    0.0024    0.0000   
 enc_layers.3.self_attention.project_v                   (1024, 1024)        0.9995    0.0006    0.0049    -0.0000  
 enc_layers.3.self_attention.attention_out               (1024, 1024)        0.9995    -0.0002   0.0048    -0.0000  
 enc_layers.3.layernorm_before_ff.weight                 (1024,)             0.0054    1.0010    0.3254    -0.0025  
 enc_layers.3.ff.w_0                                     (2560, 1024)        0.9995    -0.0004   0.0048    -0.0000  
 enc_layers.3.ff.w_1                                     (2560, 1024)        1.0000    0.0014    0.0046    -0.0000  
 enc_layers.3.ff.w_out                                   (1024, 2560)        0.9995    0.0012    0.0057    0.0000   
 enc_layers.4.layernorm_before_attention.weight          (1024,)             0.0039    1.0000    0.1295    -0.0033  
 enc_layers.4.self_attention.project_q                   (1024, 1024)        1.0000    -0.0015   0.0018    -0.0000  
 enc_layers.4.self_attention.project_k                   (1024, 1024)        1.0010    -0.0004   0.0018    -0.0000  
 enc_layers.4.self_attention.project_v                   (1024, 1024)        0.9985    -0.0005   0.0038    -0.0000  
 enc_layers.4.self_attention.attention_out               (1024, 1024)        1.0000    0.0003    0.0040    -0.0000  
 enc_layers.4.layernorm_before_ff.weight                 (1024,)             0.0057    1.0020    0.2800    -0.0161  
 enc_layers.4.ff.w_0                                     (2560, 1024)        1.0000    -0.0003   0.0041    -0.0000  
 enc_layers.4.ff.w_1                                     (2560, 1024)        0.9990    0.0011    0.0039    0.0000   
 enc_layers.4.ff.w_out                                   (1024, 2560)        1.0000    -0.0005   0.0055    0.0000   
 enc_layers.5.layernorm_before_attention.weight          (1024,)             0.0040    1.0010    0.1375    -0.0070  
 enc_layers.5.self_attention.project_q                   (1024, 1024)        1.0000    -0.0003   0.0018    0.0000   
 enc_layers.5.self_attention.project_k                   (1024, 1024)        1.0000    -0.0021   0.0018    0.0000   
 enc_layers.5.self_attention.project_v                   (1024, 1024)        0.9995    0.0009    0.0035    0.0000   
 enc_layers.5.self_attention.attention_out               (1024, 1024)        1.0000    0.0009    0.0034    -0.0000  
 enc_layers.5.layernorm_before_ff.weight                 (1024,)             0.0057    1.0029    0.2617    -0.0097  
 enc_layers.5.ff.w_0                                     (2560, 1024)        1.0010    0.0006    0.0036    -0.0000  
 enc_layers.5.ff.w_1                                     (2560, 1024)        0.9995    -0.0006   0.0035    0.0000   
 enc_layers.5.ff.w_out                                   (1024, 2560)        1.0000    -0.0008   0.0049    -0.0000  
 enc_layers.6.layernorm_before_attention.weight          (1024,)             0.0042    1.0010    0.1144    -0.0007  
 enc_layers.6.self_attention.project_q                   (1024, 1024)        0.9990    -0.0001   0.0014    -0.0000  
 enc_layers.6.self_attention.project_k                   (1024, 1024)        0.9990    -0.0000   0.0014    0.0000   
 enc_layers.6.self_attention.project_v                   (1024, 1024)        1.0010    0.0015    0.0031    -0.0000  
 enc_layers.6.self_attention.attention_out               (1024, 1024)        1.0010    0.0003    0.0031    -0.0000  
 enc_layers.6.layernorm_before_ff.weight                 (1024,)             0.0056    1.0039    0.2407    -0.0158  
 enc_layers.6.ff.w_0                                     (2560, 1024)        0.9995    0.0001    0.0035    -0.0000  
 enc_layers.6.ff.w_1                                     (2560, 1024)        0.9990    -0.0008   0.0033    0.0000   
 enc_layers.6.ff.w_out                                   (1024, 2560)        1.0000    -0.0009   0.0046    -0.0000  
 enc_layers.7.layernorm_before_attention.weight          (1024,)             0.0043    1.0010    0.0934    -0.0048  
 enc_layers.7.self_attention.project_q                   (1024, 1024)        1.0000    -0.0006   0.0014    0.0000   
 enc_layers.7.self_attention.project_k                   (1024, 1024)        0.9995    0.0007    0.0013    -0.0000  
 enc_layers.7.self_attention.project_v                   (1024, 1024)        0.9995    -0.0000   0.0028    -0.0000  
 enc_layers.7.self_attention.attention_out               (1024, 1024)        1.0000    0.0011    0.0030    0.0000   
 enc_layers.7.layernorm_before_ff.weight                 (1024,)             0.0057    1.0039    0.1793    -0.0153  
 enc_layers.7.ff.w_0                                     (2560, 1024)        1.0000    -0.0000   0.0027    0.0000   
 enc_layers.7.ff.w_1                                     (2560, 1024)        1.0000    0.0003    0.0026    0.0000   
 enc_layers.7.ff.w_out                                   (1024, 2560)        1.0000    -0.0003   0.0044    -0.0000  
 dec_layers.0.layernorm_before_self_attention.weight     (1024,)             0.0078    1.0020    0.7505    -0.0457  
 dec_layers.0.self_attention.project_q                   (1024, 1024)        0.9995    0.0002    0.0110    0.0000   
 dec_layers.0.self_attention.project_k                   (1024, 1024)        0.9995    0.0008    0.0112    -0.0000  
 dec_layers.0.self_attention.project_v                   (1024, 1024)        1.0000    0.0004    0.0168    -0.0000  
 dec_layers.0.self_attention.attention_out               (1024, 1024)        1.0000    0.0005    0.0169    0.0000   
 dec_layers.0.layernorm_before_cross_attention.weight    (1024,)             0.0032    1.0107    0.3342    -0.2502  
 dec_layers.0.cross_attention.project_q                  (1024, 1024)        0.9990    0.0012    0.0107    -0.0000  
 dec_layers.0.cross_attention.project_k                  (1024, 1024)        1.0000    0.0010    0.0102    -0.0000  
 dec_layers.0.cross_attention.project_v                  (1024, 1024)        0.9985    -0.0002   0.0133    -0.0000  
 dec_layers.0.cross_attention.attention_out              (1024, 1024)        1.0010    -0.0003   0.0129    -0.0000  
 dec_layers.0.layernorm_before_ff.weight                 (1024,)             0.0064    0.9922    1.4609    1.1621   
 dec_layers.0.ff.w_0                                     (2560, 1024)        0.9995    -0.0007   0.0213    0.0000   
 dec_layers.0.ff.w_1                                     (2560, 1024)        0.9995    -0.0001   0.0203    0.0000   
 dec_layers.0.ff.w_out                                   (1024, 2560)        1.0000    0.0004    0.0202    -0.0000  
 dec_layers.1.layernorm_before_self_attention.weight     (1024,)             0.0074    1.0039    0.3689    -0.0402  
 dec_layers.1.self_attention.project_q                   (1024, 1024)        1.0010    -0.0003   0.0063    -0.0000  
 dec_layers.1.self_attention.project_k                   (1024, 1024)        1.0000    0.0010    0.0064    -0.0000  
 dec_layers.1.self_attention.project_v                   (1024, 1024)        0.9990    -0.0019   0.0093    0.0000   
 dec_layers.1.self_attention.attention_out               (1024, 1024)        1.0000    -0.0012   0.0088    -0.0000  
 dec_layers.1.layernorm_before_cross_attention.weight    (1024,)             0.0049    1.0088    0.1610    -0.0674  
 dec_layers.1.cross_attention.project_q                  (1024, 1024)        1.0010    0.0005    0.0048    0.0000   
 dec_layers.1.cross_attention.project_k                  (1024, 1024)        1.0000    0.0021    0.0044    -0.0000  
 dec_layers.1.cross_attention.project_v                  (1024, 1024)        0.9995    0.0013    0.0056    -0.0000  
 dec_layers.1.cross_attention.attention_out              (1024, 1024)        1.0010    0.0016    0.0071    0.0000   
 dec_layers.1.layernorm_before_ff.weight                 (1024,)             0.0082    0.9956    0.9126    0.4128   
 dec_layers.1.ff.w_0                                     (2560, 1024)        1.0000    -0.0003   0.0134    0.0000   
 dec_layers.1.ff.w_1                                     (2560, 1024)        1.0000    -0.0012   0.0129    -0.0000  
 dec_layers.1.ff.w_out                                   (1024, 2560)        0.9995    0.0001    0.0142    0.0000   
 dec_layers.2.layernorm_before_self_attention.weight     (1024,)             0.0072    1.0049    0.2639    -0.0614  
 dec_layers.2.self_attention.project_q                   (1024, 1024)        1.0000    0.0006    0.0039    -0.0000  
 dec_layers.2.self_attention.project_k                   (1024, 1024)        1.0000    -0.0024   0.0045    -0.0000  
 dec_layers.2.self_attention.project_v                   (1024, 1024)        1.0000    0.0014    0.0075    0.0000   
 dec_layers.2.self_attention.attention_out               (1024, 1024)        1.0000    0.0003    0.0072    -0.0000  
 dec_layers.2.layernorm_before_cross_attention.weight    (1024,)             0.0060    1.0078    0.1095    -0.0218  
 dec_layers.2.cross_attention.project_q                  (1024, 1024)        1.0010    -0.0007   0.0035    -0.0000  
 dec_layers.2.cross_attention.project_k                  (1024, 1024)        1.0010    0.0002    0.0034    -0.0000  
 dec_layers.2.cross_attention.project_v                  (1024, 1024)        1.0000    -0.0002   0.0040    -0.0000  
 dec_layers.2.cross_attention.attention_out              (1024, 1024)        0.9990    0.0006    0.0050    0.0000   
 dec_layers.2.layernorm_before_ff.weight                 (1024,)             0.0091    0.9990    0.7251    0.1152   
 dec_layers.2.ff.w_0                                     (2560, 1024)        1.0000    0.0007    0.0104    0.0000   
 dec_layers.2.ff.w_1                                     (2560, 1024)        0.9995    0.0000    0.0100    -0.0000  
 dec_layers.2.ff.w_out                                   (1024, 2560)        1.0010    0.0002    0.0115    0.0000   
 dec_layers.3.layernorm_before_self_attention.weight     (1024,)             0.0073    1.0059    0.2014    -0.0706  
 dec_layers.3.self_attention.project_q                   (1024, 1024)        1.0010    -0.0000   0.0021    0.0000   
 dec_layers.3.self_attention.project_k                   (1024, 1024)        1.0000    -0.0025   0.0028    0.0000   
 dec_layers.3.self_attention.project_v                   (1024, 1024)        1.0010    0.0003    0.0063    -0.0000  
 dec_layers.3.self_attention.attention_out               (1024, 1024)        1.0010    -0.0015   0.0065    0.0000   
 dec_layers.3.layernorm_before_cross_attention.weight    (1024,)             0.0062    1.0078    0.0856    -0.0229  
 dec_layers.3.cross_attention.project_q                  (1024, 1024)        1.0010    0.0005    0.0022    -0.0000  
 dec_layers.3.cross_attention.project_k                  (1024, 1024)        0.9995    -0.0015   0.0025    0.0000   
 dec_layers.3.cross_attention.project_v                  (1024, 1024)        1.0010    0.0014    0.0031    0.0000   
 dec_layers.3.cross_attention.attention_out              (1024, 1024)        0.9990    -0.0005   0.0036    -0.0000  
 dec_layers.3.layernorm_before_ff.weight                 (1024,)             0.0087    1.0039    0.5977    -0.1183  
 dec_layers.3.ff.w_0                                     (2560, 1024)        0.9995    -0.0009   0.0090    -0.0000  
 dec_layers.3.ff.w_1                                     (2560, 1024)        0.9995    0.0001    0.0087    -0.0000  
 dec_layers.3.ff.w_out                                   (1024, 2560)        1.0000    -0.0005   0.0097    0.0000   
 dec_layers.4.layernorm_before_self_attention.weight     (1024,)             0.0074    1.0059    0.1754    -0.0562  
 dec_layers.4.self_attention.project_q                   (1024, 1024)        0.9990    -0.0009   0.0011    -0.0000  
 dec_layers.4.self_attention.project_k                   (1024, 1024)        1.0000    -0.0030   0.0017    0.0000   
 dec_layers.4.self_attention.project_v                   (1024, 1024)        1.0000    0.0004    0.0052    0.0000   
 dec_layers.4.self_attention.attention_out               (1024, 1024)        1.0010    0.0001    0.0043    0.0000   
 dec_layers.4.layernorm_before_cross_attention.weight    (1024,)             0.0069    1.0059    0.0825    -0.0193  
 dec_layers.4.cross_attention.project_q                  (1024, 1024)        0.9990    0.0006    0.0017    -0.0000  
 dec_layers.4.cross_attention.project_k                  (1024, 1024)        1.0010    -0.0012   0.0021    -0.0000  
 dec_layers.4.cross_attention.project_v                  (1024, 1024)        0.9995    0.0002    0.0028    0.0000   
 dec_layers.4.cross_attention.attention_out              (1024, 1024)        1.0000    0.0003    0.0026    -0.0000  
 dec_layers.4.layernorm_before_ff.weight                 (1024,)             0.0073    1.0078    0.4912    -0.2180  
 dec_layers.4.ff.w_0                                     (2560, 1024)        1.0000    -0.0006   0.0073    0.0000   
 dec_layers.4.ff.w_1                                     (2560, 1024)        1.0000    -0.0001   0.0071    -0.0000  
 dec_layers.4.ff.w_out                                   (1024, 2560)        1.0000    0.0000    0.0088    -0.0000  
 dec_layers.5.layernorm_before_self_attention.weight     (1024,)             0.0072    1.0068    0.1630    -0.0892  
 dec_layers.5.self_attention.project_q                   (1024, 1024)        1.0000    0.0010    0.0009    -0.0000  
 dec_layers.5.self_attention.project_k                   (1024, 1024)        0.9990    0.0008    0.0016    -0.0000  
 dec_layers.5.self_attention.project_v                   (1024, 1024)        1.0000    -0.0002   0.0048    -0.0000  
 dec_layers.5.self_attention.attention_out               (1024, 1024)        0.9990    0.0007    0.0018    0.0000   
 dec_layers.5.layernorm_before_cross_attention.weight    (1024,)             0.0070    1.0068    0.0701    -0.0224  
 dec_layers.5.cross_attention.project_q                  (1024, 1024)        1.0000    -0.0002   0.0013    0.0000   
 dec_layers.5.cross_attention.project_k                  (1024, 1024)        0.9995    0.0014    0.0021    0.0000   
 dec_layers.5.cross_attention.project_v                  (1024, 1024)        0.9995    -0.0013   0.0026    -0.0000  
 dec_layers.5.cross_attention.attention_out              (1024, 1024)        1.0010    0.0004    0.0010    -0.0000  
 dec_layers.5.layernorm_before_ff.weight                 (1024,)             0.0064    1.0098    0.3833    -0.2458  
 dec_layers.5.ff.w_0                                     (2560, 1024)        1.0010    -0.0006   0.0055    -0.0000  
 dec_layers.5.ff.w_1                                     (2560, 1024)        1.0000    -0.0013   0.0054    -0.0000  
 dec_layers.5.ff.w_out                                   (1024, 2560)        0.9990    -0.0004   0.0086    0.0000   
 dec_layers.6.layernorm_before_self_attention.weight     (1024,)             0.0076    1.0059    0.1365    -0.0852  
 dec_layers.6.self_attention.project_q                   (1024, 1024)        0.9990    -0.0025   0.0008    -0.0000  
 dec_layers.6.self_attention.project_k                   (1024, 1024)        1.0010    -0.0007   0.0013    -0.0000  
 dec_layers.6.self_attention.project_v                   (1024, 1024)        1.0000    -0.0022   0.0041    -0.0000  
 dec_layers.6.self_attention.attention_out               (1024, 1024)        0.9985    -0.0012   0.0011    -0.0000  
 dec_layers.6.layernorm_before_cross_attention.weight    (1024,)             0.0072    1.0059    0.0805    -0.0258  
 dec_layers.6.cross_attention.project_q                  (1024, 1024)        1.0010    -0.0008   0.0016    -0.0000  
 dec_layers.6.cross_attention.project_k                  (1024, 1024)        0.9995    0.0015    0.0020    -0.0000  
 dec_layers.6.cross_attention.project_v                  (1024, 1024)        1.0000    -0.0000   0.0025    0.0000   
 dec_layers.6.cross_attention.attention_out              (1024, 1024)        1.0010    -0.0004   0.0005    0.0000   
 dec_layers.6.layernorm_before_ff.weight                 (1024,)             0.0046    1.0117    0.2881    -0.2329  
 dec_layers.6.ff.w_0                                     (2560, 1024)        1.0000    0.0002    0.0045    -0.0000  
 dec_layers.6.ff.w_1                                     (2560, 1024)        1.0000    -0.0001   0.0042    -0.0000  
 dec_layers.6.ff.w_out                                   (1024, 2560)        1.0010    0.0001    0.0085    0.0000   
 dec_layers.7.layernorm_before_self_attention.weight     (1024,)             0.0076    1.0068    0.1698    -0.1410  
 dec_layers.7.self_attention.project_q                   (1024, 1024)        1.0000    -0.0011   0.0011    -0.0000  
 dec_layers.7.self_attention.project_k                   (1024, 1024)        0.9995    0.0007    0.0015    0.0000   
 dec_layers.7.self_attention.project_v                   (1024, 1024)        0.9995    0.0004    0.0041    -0.0000  
 dec_layers.7.self_attention.attention_out               (1024, 1024)        0.9990    -0.0001   0.0006    -0.0000  
 dec_layers.7.layernorm_before_cross_attention.weight    (1024,)             0.0077    1.0059    0.0739    -0.0278  
 dec_layers.7.cross_attention.project_q                  (1024, 1024)        1.0010    0.0014    0.0011    0.0000   
 dec_layers.7.cross_attention.project_k                  (1024, 1024)        1.0010    -0.0009   0.0017    -0.0000  
 dec_layers.7.cross_attention.project_v                  (1024, 1024)        1.0000    0.0008    0.0023    0.0000   
 dec_layers.7.cross_attention.attention_out              (1024, 1024)        1.0010    0.0019    0.0002    -0.0000  
 dec_layers.7.layernorm_before_ff.weight                 (1024,)             0.0039    1.0127    0.2230    -0.1960  
 dec_layers.7.ff.w_0                                     (2560, 1024)        0.9995    -0.0006   0.0035    0.0000   
 dec_layers.7.ff.w_1                                     (2560, 1024)        1.0000    0.0005    0.0033    0.0000   
 dec_layers.7.ff.w_out                                   (1024, 2560)        1.0000    0.0002    0.0084    0.0000   
 layernorm_after_enc.weight                              (1024,)             0.0020    1.0117    0.6113    -0.8403  
 layernorm_after_dec.weight                              (1024,)             0.0022    1.0137    1.3955    -12.0078 
 input_embedding.weight                                  (26240, 1024)       1.0000    -0.0001   0.0129    0.0000   
 output_projection.weight                                (26240, 1024)       0.9980    -0.0005   0.0078    -0.0000  
 position_bias_enc.weight                                (32, 32)            0.9829    -0.0428   0.3967    0.0000   
 position_bias_dec.weight                                (32, 32)            1.0186    -0.0380   0.4531    -0.0000  
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0178, 0.0145, 0.0140,  ..., 0.0000, 0.0000, 0.0000],
        [0.0136, 0.0138, 0.0123,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 201, loss:  0.0137481689453125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0197, 0.0145, 0.0138,  ..., 0.0000, 0.0000, 0.0000],
        [0.0148, 0.0128, 0.0118,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 202, loss:  0.01372528076171875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0176, 0.0144, 0.0147,  ..., 0.0000, 0.0000, 0.0000],
        [0.0153, 0.0123, 0.0124,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 203, loss:  0.0136566162109375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0175, 0.0141, 0.0136,  ..., 0.0000, 0.0000, 0.0000],
        [0.0156, 0.0118, 0.0118,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 204, loss:  0.0136566162109375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0175, 0.0148, 0.0145,  ..., 0.0000, 0.0000, 0.0000],
        [0.0144, 0.0123, 0.0122,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 205, loss:  0.0136566162109375
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0174, 0.0139, 0.0141,  ..., 0.0000, 0.0000, 0.0000],
        [0.0148, 0.0114, 0.0117,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 206, loss:  0.01361846923828125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0181, 0.0140, 0.0138,  ..., 0.0000, 0.0000, 0.0000],
        [0.0149, 0.0122, 0.0106,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 207, loss:  0.0135498046875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0171, 0.0143, 0.0131,  ..., 0.0000, 0.0000, 0.0000],
        [0.0144, 0.0118, 0.0105,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 208, loss:  0.0135650634765625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0169, 0.0142, 0.0149,  ..., 0.0000, 0.0000, 0.0000],
        [0.0148, 0.0116, 0.0112,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 209, loss:  0.01348114013671875
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0170, 0.0140, 0.0143,  ..., 0.0000, 0.0000, 0.0000],
        [0.0131, 0.0117, 0.0107,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 210, loss:  0.0135040283203125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0174, 0.0139, 0.0140,  ..., 0.0000, 0.0000, 0.0000],
        [0.0152, 0.0115, 0.0114,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 211, loss:  0.01349639892578125
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0170, 0.0146, 0.0133,  ..., 0.0000, 0.0000, 0.0000],
        [0.0142, 0.0117, 0.0112,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 212, loss:  0.0134429931640625
enc_length:  tensor([257,   6], device='cuda:0', dtype=torch.int32)
dec_length:  tensor([457,  50], device='cuda:0', dtype=torch.int32)
reuslt:  tensor([[ 6037, 10489,   499,  ...,  3746, 11232,  4329],
        [  731,  4994,  9916,  ...,  1916, 17898,  4081]], device='cuda:0')
target:  tensor([[ 6037, 10489,   499,  ..., 21036,  2906,  4220],
        [  731,  4994,  9916,  ..., 17982, 19467, 20987]], device='cuda:0')
loss:  tensor([[0.0167, 0.0143, 0.0136,  ..., 0.0000, 0.0000, 0.0000],
        [0.0150, 0.0125, 0.0109,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SWhereBackward0>)
Iter 213, loss:  0.013427734375
